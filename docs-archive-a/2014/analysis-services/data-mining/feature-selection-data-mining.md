---
title: Seleção de recursos (mineração de dados) | Microsoft Docs
ms.custom: ''
ms.date: 03/06/2017
ms.prod: sql-server-2014
ms.reviewer: ''
ms.technology: analysis-services
ms.topic: conceptual
helpviewer_keywords:
- mining models [Analysis Services], feature selections
- attributes [data mining]
- feature selection algorithms [Analysis Services]
- data mining [Analysis Services], feature selections
- neural network algorithms [Analysis Services]
- naive bayes algorithms [Analysis Services]
- decision tree algorithms [Analysis Services]
- datasets [Analysis Services]
- clustering algorithms [Analysis Services]
- coding [Data Mining]
ms.assetid: b044e785-4875-45ab-8ae4-cd3b4e3033bb
author: minewiskan
ms.author: owend
ms.openlocfilehash: ef5ee56636e7710074a893aed733905e1bf983bd
ms.sourcegitcommit: ad4d92dce894592a259721a1571b1d8736abacdb
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 08/04/2020
ms.locfileid: "87575457"
---
# <a name="feature-selection-data-mining"></a><span data-ttu-id="d03ae-102">Seleção de recursos (mineração de dados)</span><span class="sxs-lookup"><span data-stu-id="d03ae-102">Feature Selection (Data Mining)</span></span>
  <span data-ttu-id="d03ae-103">A *seleção de recursos* é um termo normalmente usado em Data Mining para descrever as ferramentas e as técnicas disponíveis para reduzir as entradas para um tamanho gerenciável para processamento e análise.</span><span class="sxs-lookup"><span data-stu-id="d03ae-103">*Feature selection* is a term commonly used in data mining to describe the tools and techniques available for reducing inputs to a manageable size for processing and analysis.</span></span> <span data-ttu-id="d03ae-104">A seleção de recursos implica não apenas *redução de cardinalidade*, o que significa a imposição de um corte arbitrário ou predefinido no número de atributos que podem ser considerados ao criar um modelo, mas também à escolha de atributos, o que significa que o analista ou a ferramenta de modelagem seleciona ou descarta os atributos de forma ativa com base em sua utilidade para análise.</span><span class="sxs-lookup"><span data-stu-id="d03ae-104">Feature selection implies not only *cardinality reduction*, which means imposing an arbitrary or predefined cutoff on the number of attributes that can be considered when building a model, but also the choice of attributes, meaning that either the analyst or the modeling tool actively selects or discards attributes based on their usefulness for analysis.</span></span>  
  
 <span data-ttu-id="d03ae-105">A capacidade para aplicar seleção de recursos é crítica para análise efetiva, porque os conjuntos de dados frequentemente contêm muito mais informações do que é necessário para criar o modelo.</span><span class="sxs-lookup"><span data-stu-id="d03ae-105">The ability to apply feature selection is critical for effective analysis, because datasets frequently contain far more information than is needed to build the model.</span></span> <span data-ttu-id="d03ae-106">Por exemplo, um conjunto de dados pode conter 500 colunas que descrevem as características de clientes, mas se os dados em algumas das colunas forem muito esparsos, você ganharia um benefício muito pequeno por acrescentá-los ao modelo.</span><span class="sxs-lookup"><span data-stu-id="d03ae-106">For example, a dataset might contain 500 columns that describe the characteristics of customers, but if the data in some of the columns is very sparse you would gain very little benefit from adding them to the model.</span></span> <span data-ttu-id="d03ae-107">Se você mantiver colunas desnecessárias quando criar o modelo, precisará de mais CPU e memória durante o processo de treinamento e de mais espaço de armazenamento para o modelo completo.</span><span class="sxs-lookup"><span data-stu-id="d03ae-107">If you keep the unneeded columns while building the model, more CPU and memory are required during the training process, and more storage space is required for the completed model.</span></span>  
  
 <span data-ttu-id="d03ae-108">Ainda que recursos não sejam um problema, normalmente você remove colunas desnecessárias porque elas podem diminuir a qualidade dos padrões descobertos, pelos seguintes motivos:</span><span class="sxs-lookup"><span data-stu-id="d03ae-108">Even if resources are not an issue, you typically want to remove unneeded columns because they might degrade the quality of discovered patterns, for the following reasons:</span></span>  
  
-   <span data-ttu-id="d03ae-109">Algumas colunas são ruidosas ou redundantes.</span><span class="sxs-lookup"><span data-stu-id="d03ae-109">Some columns are noisy or redundant.</span></span> <span data-ttu-id="d03ae-110">Esse ruído dificulta a descoberta de padrões significantes a partir dos dados;</span><span class="sxs-lookup"><span data-stu-id="d03ae-110">This noise makes it more difficult to discover meaningful patterns from the data;</span></span>  
  
-   <span data-ttu-id="d03ae-111">Para descobrir padrões de qualidade, a maioria que algoritmos de mineração de dados requer um conjunto de dados de treinamento muito maior no conjunto de dados de grande dimensão.</span><span class="sxs-lookup"><span data-stu-id="d03ae-111">To discover quality patterns, most data mining algorithms require much larger training data set on high-dimensional data set.</span></span> <span data-ttu-id="d03ae-112">Mas os dados de treinamento são muito pequenos em alguns aplicativos de mineração de dados.</span><span class="sxs-lookup"><span data-stu-id="d03ae-112">But the training data is very small in some data mining applications.</span></span>  
  
 <span data-ttu-id="d03ae-113">Se somente 50 das 500 colunas na fonte de dados tiverem informações úteis para criar um modelo, você poderá apenas omiti-las do modelo ou pode usar técnicas de seleção de recursos para descobrir automaticamente os melhores recursos e excluir valores que são estatisticamente insignificantes.</span><span class="sxs-lookup"><span data-stu-id="d03ae-113">If only 50 of the 500 columns in the data source have information that is useful in building a model, you could just leave them out of the model, or you could use feature selection techniques to automatically discover the best features and to exclude values that are statistically insignificant.</span></span> <span data-ttu-id="d03ae-114">A seleção de recursos ajuda a resolver os problemas de ter dados demais de pouco valor, ou de ter pouquíssimos dados de alto valor.</span><span class="sxs-lookup"><span data-stu-id="d03ae-114">Feature selection helps solve the twin problems of having too much data that is of little value, or having too little data that is of high value.</span></span>  
  
## <a name="feature-selection-in-analysis-services-data-mining"></a><span data-ttu-id="d03ae-115">Seleção de recursos na mineração de dados do Analysis Services</span><span class="sxs-lookup"><span data-stu-id="d03ae-115">Feature Selection in Analysis Services Data Mining</span></span>  
 <span data-ttu-id="d03ae-116">Normalmente, a seleção de recursos é executada automaticamente no [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] e cada algoritmo tem um conjunto de técnicas padrão para aplicar redução de recursos de maneira inteligente.</span><span class="sxs-lookup"><span data-stu-id="d03ae-116">Usually, feature selection is performed automatically in [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)], and each algorithm has a set of default techniques for intelligently applying feature reduction.</span></span> <span data-ttu-id="d03ae-117">A seleção de recursos sempre é feita antes do treinamento do modelo, para que os atributos de um conjunto de dados com maior probabilidade de uso no modelo sejam escolhidos de forma automática.</span><span class="sxs-lookup"><span data-stu-id="d03ae-117">Feature selection is always performed before the model is trained, to automatically choose the attributes in a dataset that are most likely to be used in the model.</span></span> <span data-ttu-id="d03ae-118">Porém, você também pode definir manualmente parâmetros para influenciar o comportamento de seleção de recursos.</span><span class="sxs-lookup"><span data-stu-id="d03ae-118">However, you can also manually set parameters to influence feature selection behavior.</span></span>  
  
 <span data-ttu-id="d03ae-119">Em geral, ela funciona calculando uma pontuação para cada atributo e, em seguida, selecionando apenas os atributos com a pontuação mais alta.</span><span class="sxs-lookup"><span data-stu-id="d03ae-119">In general, feature selection works by calculating a score for each attribute, and then selecting only the attributes that have the best scores.</span></span> <span data-ttu-id="d03ae-120">Também é possível ajustar o limiar para os pontos mais altos.</span><span class="sxs-lookup"><span data-stu-id="d03ae-120">You can also adjust the threshold for the top scores.</span></span> <span data-ttu-id="d03ae-121">O [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] fornece vários métodos para calcular estas pontuações e o método exato que é aplicado em qualquer modelo depende destes fatores:</span><span class="sxs-lookup"><span data-stu-id="d03ae-121">[!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] provides multiple methods for calculating these scores, and the exact method that is applied in any model depends on these factors:</span></span>  
  
-   <span data-ttu-id="d03ae-122">O algoritmo usado em seu modelo</span><span class="sxs-lookup"><span data-stu-id="d03ae-122">The algorithm used in your model</span></span>  
  
-   <span data-ttu-id="d03ae-123">O tipo de dados do atributo</span><span class="sxs-lookup"><span data-stu-id="d03ae-123">The data type of the attribute</span></span>  
  
-   <span data-ttu-id="d03ae-124">Os parâmetros que você pode ter definido em seu modelo</span><span class="sxs-lookup"><span data-stu-id="d03ae-124">Any parameters that you may have set on your model</span></span>  
  
 <span data-ttu-id="d03ae-125">A seleção de recursos é aplicada a entradas, atributos previsíveis ou estados em uma coluna.</span><span class="sxs-lookup"><span data-stu-id="d03ae-125">Feature selection is applied to inputs, predictable attributes, or to states in a column.</span></span> <span data-ttu-id="d03ae-126">Quando a pontuação para a seleção de recursos estiver concluída, somente os atributos e os estados que o algoritmo selecionar serão incluídos no processo de criação de modelo e poderão ser usados para previsão.</span><span class="sxs-lookup"><span data-stu-id="d03ae-126">When scoring for feature selection is complete, only the attributes and states that the algorithm selects are included in the model-building process and can be used for prediction.</span></span> <span data-ttu-id="d03ae-127">Se você escolher um atributo previsível que não atende o limite para seleção de recursos, o atributo ainda poderá ser usado para previsão, mas as previsões serão baseadas somente nas estatísticas globais que existem no modelo.</span><span class="sxs-lookup"><span data-stu-id="d03ae-127">If you choose a predictable attribute that does not meet the threshold for feature selection the attribute can still be used for prediction, but the predictions will be based solely on the global statistics that exist in the model.</span></span>  
  
> [!NOTE]  
>  <span data-ttu-id="d03ae-128">A seleção de recursos afeta apenas as colunas usadas no modelo e não o armazenamento da estrutura de mineração.</span><span class="sxs-lookup"><span data-stu-id="d03ae-128">Feature selection affects only the columns that are used in the model, and has no effect on storage of the mining structure.</span></span> <span data-ttu-id="d03ae-129">As colunas que ficarem fora do modelo de mineração continuarão disponíveis na estrutura, e os dados das colunas da estrutura de mineração serão armazenados em cache.</span><span class="sxs-lookup"><span data-stu-id="d03ae-129">The columns that you leave out of the mining model are still available in the structure, and data in the mining structure columns will be cached.</span></span>  
  
### <a name="definition-of-feature-selection-methods"></a><span data-ttu-id="d03ae-130">Definição de métodos de seleção de recursos</span><span class="sxs-lookup"><span data-stu-id="d03ae-130">Definition of Feature Selection Methods</span></span>  
 <span data-ttu-id="d03ae-131">Há várias formas de implementar a seleção de recursos, dependendo do tipo de dados com que você está trabalhando e do algoritmo escolhido para a análise.</span><span class="sxs-lookup"><span data-stu-id="d03ae-131">There are many ways to implement feature selection, depending on the type of data that you are working with and the algorithm that you choose for analysis.</span></span> <span data-ttu-id="d03ae-132">O SQL Server Analysis Services fornece vários métodos populares e bem-estabelecidos para pontuar atributos.</span><span class="sxs-lookup"><span data-stu-id="d03ae-132">SQL Server Analysis Services provides several popular and well-established methods for scoring attributes.</span></span> <span data-ttu-id="d03ae-133">O método aplicado em qualquer algoritmo ou conjunto de dados depende dos tipos de dados e do uso de coluna.</span><span class="sxs-lookup"><span data-stu-id="d03ae-133">The method that is applied in any algorithm or data set depends on the data types, and the column usage.</span></span>  
  
 <span data-ttu-id="d03ae-134">A pontuação de *interesse* é usada para classificar e ordenar atributos em colunas que contêm dados numéricos contínuos não binários.</span><span class="sxs-lookup"><span data-stu-id="d03ae-134">The *interestingness* score is used to rank and sort attributes in columns that contain nonbinary continuous numeric data.</span></span>  
  
 <span data-ttu-id="d03ae-135">A*entropia de Shannon* e duas pontuações *Bayesiana* estão disponíveis para colunas que contêm dados discretos e diferenciados.</span><span class="sxs-lookup"><span data-stu-id="d03ae-135">*Shannon's entropy* and two *Bayesian* scores are available for columns that contain discrete and discretized data.</span></span> <span data-ttu-id="d03ae-136">No entanto, se o modelo contiver colunas contínuas, a pontuação de interesse será usada para avaliar todas as colunas de entrada para garantir a consistência.</span><span class="sxs-lookup"><span data-stu-id="d03ae-136">However, if the model contains any continuous columns, the interestingness score will be used to assess all input columns, to ensure consistency.</span></span>  
  
 <span data-ttu-id="d03ae-137">A seção a seguir descreve cada método de seleção de recursos.</span><span class="sxs-lookup"><span data-stu-id="d03ae-137">The following section describes each method of feature selection.</span></span>  
  
#### <a name="interestingness-score"></a><span data-ttu-id="d03ae-138">Pontuação de interesse</span><span class="sxs-lookup"><span data-stu-id="d03ae-138">Interestingness score</span></span>  
 <span data-ttu-id="d03ae-139">Um recurso será interessante se ele transmitir alguma informação útil.</span><span class="sxs-lookup"><span data-stu-id="d03ae-139">A feature is interesting if it tells you some useful piece of information.</span></span> <span data-ttu-id="d03ae-140">Como a definição do que é útil varia dependendo do cenário, a Data Mining setor desenvolveu várias maneiras de medir a *curiosaidade*.</span><span class="sxs-lookup"><span data-stu-id="d03ae-140">Because the definition of what is useful varies depending on the scenario, the data mining industry has developed various ways to measure *interestingness*.</span></span> <span data-ttu-id="d03ae-141">Por exemplo, *novidade* pode ser interessante na detecção de exceção, mas a capacidade de discriminar várias entre itens relacionados ou o *peso de discriminamento*pode ser mais interessante para classificação.</span><span class="sxs-lookup"><span data-stu-id="d03ae-141">For example, *novelty* might be interesting in outlier detection, but the ability to discriminate between closely related items, or *discriminating weight*, might be more interesting for classification.</span></span>  
  
 <span data-ttu-id="d03ae-142">A medida de interesse usada em SQL Server Analysis Services é *baseada em entropia*, o que significa que os atributos com distribuições aleatórias têm maior entropia e menor lucro de informações; Portanto, esses atributos são menos interessantes.</span><span class="sxs-lookup"><span data-stu-id="d03ae-142">The measure of interestingness that is used in SQL Server Analysis Services is *entropy-based*, meaning that attributes with random distributions have higher entropy and lower information gain; therefore, such attributes are less interesting.</span></span> <span data-ttu-id="d03ae-143">A entropia de qualquer atributo em particular é comparada à entropia de todos os outros atributos, como segue:</span><span class="sxs-lookup"><span data-stu-id="d03ae-143">The entropy for any particular attribute is compared to the entropy of all other attributes, as follows:</span></span>  
  
 <span data-ttu-id="d03ae-144">Interestingness(Attribute) = - (m - Entropy(Attribute)) \* (m - Entropy(Attribute))</span><span class="sxs-lookup"><span data-stu-id="d03ae-144">Interestingness(Attribute) = - (m - Entropy(Attribute)) \* (m - Entropy(Attribute))</span></span>  
  
 <span data-ttu-id="d03ae-145">Entropia central ou m, significa a entropia de todo o conjunto de recursos.</span><span class="sxs-lookup"><span data-stu-id="d03ae-145">Central entropy, or m, means the entropy of the entire feature set.</span></span> <span data-ttu-id="d03ae-146">Ao subtrair a entropia do atributo de destino da entropia central, é possível avaliar a quantidade de informações fornecida pelo atributo.</span><span class="sxs-lookup"><span data-stu-id="d03ae-146">By subtracting the entropy of the target attribute from the central entropy, you can assess how much information the attribute provides.</span></span>  
  
 <span data-ttu-id="d03ae-147">Por padrão, essa pontuação será usada sempre que a coluna contiver dados numéricos contínuos não binários.</span><span class="sxs-lookup"><span data-stu-id="d03ae-147">This score is used by default whenever the column contains nonbinary continuous numeric data.</span></span>  
  
#### <a name="shannons-entropy"></a><span data-ttu-id="d03ae-148">Entropia de Shannon</span><span class="sxs-lookup"><span data-stu-id="d03ae-148">Shannon's Entropy</span></span>  
 <span data-ttu-id="d03ae-149">A entropia de Shannon mede a incerteza de uma variável aleatória para um resultado em particular.</span><span class="sxs-lookup"><span data-stu-id="d03ae-149">Shannon's entropy measures the uncertainty of a random variable for a particular outcome.</span></span> <span data-ttu-id="d03ae-150">Por exemplo, a entropia do lançamento de uma moeda pode ser representada como uma função da probabilidade de o resultado ser cara.</span><span class="sxs-lookup"><span data-stu-id="d03ae-150">For example, the entropy of a coin toss can be represented as a function of the probability of it coming up heads.</span></span>  
  
 <span data-ttu-id="d03ae-151">O Analysis Services usa a seguinte fórmula para calcular a entropia de Shannon:</span><span class="sxs-lookup"><span data-stu-id="d03ae-151">Analysis Services uses the following formula to calculate Shannon's entropy:</span></span>  
  
 <span data-ttu-id="d03ae-152">H(X) = -∑ P(xi) log(P(xi))</span><span class="sxs-lookup"><span data-stu-id="d03ae-152">H(X) = -∑ P(xi) log(P(xi))</span></span>  
  
 <span data-ttu-id="d03ae-153">Esse método de pontuação está disponível para atributos discretos e diferenciados.</span><span class="sxs-lookup"><span data-stu-id="d03ae-153">This scoring method is available for discrete and discretized attributes.</span></span>  
  
#### <a name="bayesian-with-k2-prior"></a><span data-ttu-id="d03ae-154">Bayesian com K2 a priori</span><span class="sxs-lookup"><span data-stu-id="d03ae-154">Bayesian with K2 Prior</span></span>  
 <span data-ttu-id="d03ae-155">O Analysis Services fornece duas pontuações para seleção de recursos que se baseiam em redes Bayesianas.</span><span class="sxs-lookup"><span data-stu-id="d03ae-155">Analysis Services provides two feature selection scores that are based on Bayesian networks.</span></span> <span data-ttu-id="d03ae-156">Uma rede Bayesiana é um gráfico *direcionado* ou *acíclico* de estados e transições entre estados, ou seja, alguns estados vêm sempre antes do estado atual, alguns ocorrem depois, e o gráfico não se repete nem gera um loop.</span><span class="sxs-lookup"><span data-stu-id="d03ae-156">A Bayesian network is a *directed* or *acyclic* graph of states and transitions between states, meaning that some states are always prior to the current state, some states are posterior, and the graph does not repeat or loop.</span></span> <span data-ttu-id="d03ae-157">Por definição, as redes Bayesianas permitem o uso do conhecimento prévio.</span><span class="sxs-lookup"><span data-stu-id="d03ae-157">By definition, Bayesian networks allow the use of prior knowledge.</span></span> <span data-ttu-id="d03ae-158">No entanto, a questão de qual estado anterior usar no cálculo de probabilidades de estados posteriores é importante para o design, o desempenho e a precisão do algoritmo.</span><span class="sxs-lookup"><span data-stu-id="d03ae-158">However, the question of which prior states to use in calculating probabilities of later states is important for algorithm design, performance, and accuracy.</span></span>  
  
 <span data-ttu-id="d03ae-159">O algoritmo K2 para aprender com a rede Bayesiana foi desenvolvido por Cooper e Herskovits e é usado com frequência na mineração de dados.</span><span class="sxs-lookup"><span data-stu-id="d03ae-159">The K2 algorithm for learning from a Bayesian network was developed by Cooper and Herskovits and is often used in data mining.</span></span> <span data-ttu-id="d03ae-160">Ele é escalável e analisa diversas variáveis, mas requer ordenação das variáveis usadas como entrada.</span><span class="sxs-lookup"><span data-stu-id="d03ae-160">It is scalable and can analyze multiple variables, but requires ordering on variables used as input.</span></span> <span data-ttu-id="d03ae-161">Para obter mais informações, consulte [Learning Bayesian Networks](https://go.microsoft.com/fwlink/?LinkId=105885) (em inglês) de Chickering, Geiger e Heckerman.</span><span class="sxs-lookup"><span data-stu-id="d03ae-161">For more information, see [Learning Bayesian Networks](https://go.microsoft.com/fwlink/?LinkId=105885) by Chickering, Geiger, and Heckerman.</span></span>  
  
 <span data-ttu-id="d03ae-162">Esse método de pontuação está disponível para atributos discretos e diferenciados.</span><span class="sxs-lookup"><span data-stu-id="d03ae-162">This scoring method is available for discrete and discretized attributes.</span></span>  
  
#### <a name="bayesian-dirichlet-equivalent-with-uniform-prior"></a><span data-ttu-id="d03ae-163">Bayesiano Dirichlet Equivalente com Uniforme a priori</span><span class="sxs-lookup"><span data-stu-id="d03ae-163">Bayesian Dirichlet Equivalent with Uniform Prior</span></span>  
 <span data-ttu-id="d03ae-164">A pontuação BDE (Bayesiano Dirichlet Equivalente) também usa análise Bayesiana para avaliar uma rede dado um conjunto de dados.</span><span class="sxs-lookup"><span data-stu-id="d03ae-164">The Bayesian Dirichlet Equivalent (BDE) score also uses Bayesian analysis to evaluate a network given a dataset.</span></span> <span data-ttu-id="d03ae-165">O método de pontuação do BDE foi desenvolvido por Heckerman e se baseia na métrica de BD desenvolvida por Cooper e Herskovits.</span><span class="sxs-lookup"><span data-stu-id="d03ae-165">The BDE scoring method was developed by Heckerman and is based on the BD metric developed by Cooper and Herskovits.</span></span> <span data-ttu-id="d03ae-166">A distribuição Dirichlet é uma distribuição multinomial que descreve a probabilidade condicional de cada variável da rede e possui muitas propriedades que devemos conhecer.</span><span class="sxs-lookup"><span data-stu-id="d03ae-166">The Dirichlet distribution is a multinomial distribution that describes the conditional probability of each variable in the network, and has many properties that are useful for learning.</span></span>  
  
 <span data-ttu-id="d03ae-167">O método BDEU (Bayesiano Dirichlet Equivalente com Uniforme a priori) assume um caso especial da distribuição Dirichlet, na qual uma constante matemática é usada para criar uma distribuição fixa ou uniforme de estados anteriores.</span><span class="sxs-lookup"><span data-stu-id="d03ae-167">The Bayesian Dirichlet Equivalent with Uniform Prior (BDEU) method assumes a special case of the Dirichlet distribution, in which a mathematical constant is used to create a fixed or uniform distribution of prior states.</span></span> <span data-ttu-id="d03ae-168">A pontuação do BDE também assume equivalência de probabilidade, o que significa que não se pode esperar que os dados separem estruturas equivalentes.</span><span class="sxs-lookup"><span data-stu-id="d03ae-168">The BDE score also assumes likelihood equivalence, which means that the data cannot be expected to discriminate equivalent structures.</span></span> <span data-ttu-id="d03ae-169">Em outras palavras, se a pontuação de Se A Então B for igual à pontuação de Se B Então A, não será possível distinguir as estruturas com base nos dados nem deduzir a causa.</span><span class="sxs-lookup"><span data-stu-id="d03ae-169">In other words, if the score for If A Then B is the same as the score for If B Then A, the structures cannot be distinguished based on the data, and causation cannot be inferred.</span></span>  
  
 <span data-ttu-id="d03ae-170">Para obter mais informações sobre redes Bayesianas e a implementação desses métodos de pontuação, consulte [Learning Bayesian Networks](https://go.microsoft.com/fwlink/?LinkId=105885)(em inglês).</span><span class="sxs-lookup"><span data-stu-id="d03ae-170">For more information about Bayesian networks and the implementation of these scoring methods, see [Learning Bayesian Networks](https://go.microsoft.com/fwlink/?LinkId=105885).</span></span>  
  
### <a name="feature-selection-methods-used-by-analysis-services-algorithms"></a><span data-ttu-id="d03ae-171">Métodos de seleção de recursos usados pelos algoritmos do Analysis Services</span><span class="sxs-lookup"><span data-stu-id="d03ae-171">Feature Selection Methods used by Analysis Services Algorithms</span></span>  
 <span data-ttu-id="d03ae-172">A tabela a seguir lista os algoritmos que suportam a seleção de recursos, os métodos de seleção de recursos usados por eles e os parâmetros que você define para controlar o comportamento da seleção de recursos:</span><span class="sxs-lookup"><span data-stu-id="d03ae-172">The following table lists the algorithms that support feature selection, the feature selection methods used by the algorithm, and the parameters that you set to control feature selection behavior:</span></span>  
  
|<span data-ttu-id="d03ae-173">Algoritmo</span><span class="sxs-lookup"><span data-stu-id="d03ae-173">Algorithm</span></span>|<span data-ttu-id="d03ae-174">Método de análise</span><span class="sxs-lookup"><span data-stu-id="d03ae-174">Method of analysis</span></span>|<span data-ttu-id="d03ae-175">Comentários</span><span class="sxs-lookup"><span data-stu-id="d03ae-175">Comments</span></span>|  
|---------------|------------------------|--------------|  
|<span data-ttu-id="d03ae-176">Naive Bayes</span><span class="sxs-lookup"><span data-stu-id="d03ae-176">Naive Bayes</span></span>|<span data-ttu-id="d03ae-177">Entropia de Shannon</span><span class="sxs-lookup"><span data-stu-id="d03ae-177">Shannon's Entropy</span></span><br /><br /> <span data-ttu-id="d03ae-178">Bayesian com K2 a priori</span><span class="sxs-lookup"><span data-stu-id="d03ae-178">Bayesian with K2 Prior</span></span><br /><br /> <span data-ttu-id="d03ae-179">Bayesian Dirichlet com uniforme a priori (padrão)</span><span class="sxs-lookup"><span data-stu-id="d03ae-179">Bayesian Dirichlet with uniform prior (default)</span></span>|<span data-ttu-id="d03ae-180">O algoritmo Microsoft Naïve Bayes aceita somente atributos discretos ou diferenciados; portanto, não pode usar a pontuação de interesse.</span><span class="sxs-lookup"><span data-stu-id="d03ae-180">The Microsoft Naïve Bayes algorithm accepts only discrete or discretized attributes; therefore, it cannot use the interestingness score.</span></span><br /><br /> <span data-ttu-id="d03ae-181">Para obter mais informações sobre esse algoritmo, consulte [Microsoft Naive Bayes Algorithm Technical Reference](microsoft-naive-bayes-algorithm-technical-reference.md).</span><span class="sxs-lookup"><span data-stu-id="d03ae-181">For more information about this algorithm, see [Microsoft Naive Bayes Algorithm Technical Reference](microsoft-naive-bayes-algorithm-technical-reference.md).</span></span>|  
|<span data-ttu-id="d03ae-182">Árvores de decisão</span><span class="sxs-lookup"><span data-stu-id="d03ae-182">Decision trees</span></span>|<span data-ttu-id="d03ae-183">Pontuação de interesse</span><span class="sxs-lookup"><span data-stu-id="d03ae-183">Interestingness score</span></span><br /><br /> <span data-ttu-id="d03ae-184">Entropia de Shannon</span><span class="sxs-lookup"><span data-stu-id="d03ae-184">Shannon's Entropy</span></span><br /><br /> <span data-ttu-id="d03ae-185">Bayesian com K2 a priori</span><span class="sxs-lookup"><span data-stu-id="d03ae-185">Bayesian with K2 Prior</span></span><br /><br /> <span data-ttu-id="d03ae-186">Bayesian Dirichlet com uniforme a priori (padrão)</span><span class="sxs-lookup"><span data-stu-id="d03ae-186">Bayesian Dirichlet with uniform prior (default)</span></span>|<span data-ttu-id="d03ae-187">Se qualquer coluna contiver valores contínuos não binários, a pontuação de interesse será usada em todas as colunas para garantir a consistência.</span><span class="sxs-lookup"><span data-stu-id="d03ae-187">If any columns contain non-binary continuous values, the interestingness score is used for all columns, to ensure consistency.</span></span> <span data-ttu-id="d03ae-188">Caso contrário, será usado o método de seleção de recursos padrão ou o método que você especificou quando criou o modelo.</span><span class="sxs-lookup"><span data-stu-id="d03ae-188">Otherwise, the default feature selection method is used, or the method that you specified when you created the model.</span></span><br /><br /> <span data-ttu-id="d03ae-189">Para obter mais informações sobre esse algoritmo, consulte [Microsoft Decision Trees Algorithm Technical Reference](microsoft-decision-trees-algorithm-technical-reference.md).</span><span class="sxs-lookup"><span data-stu-id="d03ae-189">For more information about this algorithm, see [Microsoft Decision Trees Algorithm Technical Reference](microsoft-decision-trees-algorithm-technical-reference.md).</span></span>|  
|<span data-ttu-id="d03ae-190">Rede neural</span><span class="sxs-lookup"><span data-stu-id="d03ae-190">Neural network</span></span>|<span data-ttu-id="d03ae-191">Pontuação de interesse</span><span class="sxs-lookup"><span data-stu-id="d03ae-191">Interestingness score</span></span><br /><br /> <span data-ttu-id="d03ae-192">Entropia de Shannon</span><span class="sxs-lookup"><span data-stu-id="d03ae-192">Shannon's Entropy</span></span><br /><br /> <span data-ttu-id="d03ae-193">Bayesian com K2 a priori</span><span class="sxs-lookup"><span data-stu-id="d03ae-193">Bayesian with K2 Prior</span></span><br /><br /> <span data-ttu-id="d03ae-194">Bayesian Dirichlet com uniforme a priori (padrão)</span><span class="sxs-lookup"><span data-stu-id="d03ae-194">Bayesian Dirichlet with uniform prior (default)</span></span>|<span data-ttu-id="d03ae-195">O algoritmo Redes Neurais da Microsoft pode usar ambos os métodos Bayesiano e baseado em entropia, desde que os dados contenham colunas contínuas.</span><span class="sxs-lookup"><span data-stu-id="d03ae-195">The Microsoft Neural Networks algorithm can use both Bayesian and entropy-based methods, as long as the data contains continuous columns.</span></span><br /><br /> <span data-ttu-id="d03ae-196">Para obter mais informações sobre esse algoritmo, consulte [Microsoft Neural Network Algorithm Technical Reference](microsoft-neural-network-algorithm-technical-reference.md).</span><span class="sxs-lookup"><span data-stu-id="d03ae-196">For more information about this algorithm, see [Microsoft Neural Network Algorithm Technical Reference](microsoft-neural-network-algorithm-technical-reference.md).</span></span>|  
|<span data-ttu-id="d03ae-197">Regressão logística</span><span class="sxs-lookup"><span data-stu-id="d03ae-197">Logistic regression</span></span>|<span data-ttu-id="d03ae-198">Pontuação de interesse</span><span class="sxs-lookup"><span data-stu-id="d03ae-198">Interestingness score</span></span><br /><br /> <span data-ttu-id="d03ae-199">Entropia de Shannon</span><span class="sxs-lookup"><span data-stu-id="d03ae-199">Shannon's Entropy</span></span><br /><br /> <span data-ttu-id="d03ae-200">Bayesian com K2 a priori</span><span class="sxs-lookup"><span data-stu-id="d03ae-200">Bayesian with K2 Prior</span></span><br /><br /> <span data-ttu-id="d03ae-201">Bayesian Dirichlet com uniforme a priori (padrão)</span><span class="sxs-lookup"><span data-stu-id="d03ae-201">Bayesian Dirichlet with uniform prior (default)</span></span>|<span data-ttu-id="d03ae-202">Embora o algoritmo de Regressão Logística da Microsoft se baseie no algoritmo Rede Neural da Microsoft, você não pode personalizar modelos de regressão logística para controlar o comportamento de seleção de recursos; portanto, a seleção de recursos sempre usa o método mais apropriado para o atributo por padrão.</span><span class="sxs-lookup"><span data-stu-id="d03ae-202">Although the Microsoft Logistic Regression algorithm is based on the Microsoft Neural Network algorithm, you cannot customize logistic regression models to control feature selection behavior; therefore, feature selection always default to the method that is most appropriate for the attribute.</span></span><br /><br /> <span data-ttu-id="d03ae-203">Se todos os atributos forem discretos ou diferenciados, o padrão será BDEU.</span><span class="sxs-lookup"><span data-stu-id="d03ae-203">If all attributes are discrete or discretized, the default is BDEU.</span></span><br /><br /> <span data-ttu-id="d03ae-204">Para obter mais informações sobre esse algoritmo, consulte [Microsoft Logistic Regression Algorithm Technical Reference](microsoft-logistic-regression-algorithm-technical-reference.md).</span><span class="sxs-lookup"><span data-stu-id="d03ae-204">For more information about this algorithm, see [Microsoft Logistic Regression Algorithm Technical Reference](microsoft-logistic-regression-algorithm-technical-reference.md).</span></span>|  
|<span data-ttu-id="d03ae-205">Clustering</span><span class="sxs-lookup"><span data-stu-id="d03ae-205">Clustering</span></span>|<span data-ttu-id="d03ae-206">Pontuação de interesse</span><span class="sxs-lookup"><span data-stu-id="d03ae-206">Interestingness score</span></span>|<span data-ttu-id="d03ae-207">O algoritmo Microsoft Clustering pode usar dados discretos ou diferenciados.</span><span class="sxs-lookup"><span data-stu-id="d03ae-207">The Microsoft Clustering algorithm can use discrete or discretized data.</span></span> <span data-ttu-id="d03ae-208">No entanto, como a pontuação de cada atributo é calculada como uma distância e representada como um número contínuo, a pontuação de interesse deve ser usada.</span><span class="sxs-lookup"><span data-stu-id="d03ae-208">However, because the score of each attribute is calculated as a distance and is represented as a continuous number, the interestingness score must be used.</span></span><br /><br /> <span data-ttu-id="d03ae-209">Para obter mais informações sobre esse algoritmo, consulte [Microsoft Clustering Algorithm Technical Reference](microsoft-clustering-algorithm-technical-reference.md).</span><span class="sxs-lookup"><span data-stu-id="d03ae-209">For more information about this algorithm, see [Microsoft Clustering Algorithm Technical Reference](microsoft-clustering-algorithm-technical-reference.md).</span></span>|  
|<span data-ttu-id="d03ae-210">Regressão linear</span><span class="sxs-lookup"><span data-stu-id="d03ae-210">Linear regression</span></span>|<span data-ttu-id="d03ae-211">Pontuação de interesse</span><span class="sxs-lookup"><span data-stu-id="d03ae-211">Interestingness score</span></span>|<span data-ttu-id="d03ae-212">O algoritmo de Regressão Linear da Microsoft pode usar somente a pontuação de interesse, pois suporta apenas colunas contínuas.</span><span class="sxs-lookup"><span data-stu-id="d03ae-212">The Microsoft Linear Regression algorithm can only use the interestingness score, because it only supports continuous columns.</span></span><br /><br /> <span data-ttu-id="d03ae-213">Para obter mais informações sobre esse algoritmo, consulte [Microsoft Linear Regression Algorithm Technical Reference](microsoft-linear-regression-algorithm-technical-reference.md).</span><span class="sxs-lookup"><span data-stu-id="d03ae-213">For more information about this algorithm, see [Microsoft Linear Regression Algorithm Technical Reference](microsoft-linear-regression-algorithm-technical-reference.md).</span></span>|  
|<span data-ttu-id="d03ae-214">Regras da associação</span><span class="sxs-lookup"><span data-stu-id="d03ae-214">Association rules</span></span><br /><br /> <span data-ttu-id="d03ae-215">Clustering de sequências</span><span class="sxs-lookup"><span data-stu-id="d03ae-215">Sequence clustering</span></span>|<span data-ttu-id="d03ae-216">Não usado</span><span class="sxs-lookup"><span data-stu-id="d03ae-216">Not used</span></span>|<span data-ttu-id="d03ae-217">A seleção de recursos não é invocada com esses algoritmos.</span><span class="sxs-lookup"><span data-stu-id="d03ae-217">Feature selection is not invoked with these algorithms.</span></span><br /><br /> <span data-ttu-id="d03ae-218">No entanto, você poderá controlar o comportamento do algoritmo e reduzir o tamanho dos dados de entrada se necessário, configurando o valor dos parâmetros MINIMUM_SUPPORT e MINIMUM_PROBABILIITY.</span><span class="sxs-lookup"><span data-stu-id="d03ae-218">However, you can control the behavior of the algorithm and reduce the size of input data if necessary by setting the value of the parameters MINIMUM_SUPPORT and MINIMUM_PROBABILIITY.</span></span><br /><br /> <span data-ttu-id="d03ae-219">Para obter mais informações, consulte [Microsoft Association Algorithm Technical Reference](microsoft-association-algorithm-technical-reference.md) e [Microsoft Sequence Clustering Algorithm Technical Reference](microsoft-sequence-clustering-algorithm-technical-reference.md).</span><span class="sxs-lookup"><span data-stu-id="d03ae-219">For more information, see [Microsoft Association Algorithm Technical Reference](microsoft-association-algorithm-technical-reference.md) and [Microsoft Sequence Clustering Algorithm Technical Reference](microsoft-sequence-clustering-algorithm-technical-reference.md).</span></span>|  
|<span data-ttu-id="d03ae-220">Série temporal</span><span class="sxs-lookup"><span data-stu-id="d03ae-220">Time series</span></span>|<span data-ttu-id="d03ae-221">Não usado</span><span class="sxs-lookup"><span data-stu-id="d03ae-221">Not used</span></span>|<span data-ttu-id="d03ae-222">A seleção de recursos não se aplica a modelos de série temporal.</span><span class="sxs-lookup"><span data-stu-id="d03ae-222">Feature selection does not apply to time series models.</span></span><br /><br /> <span data-ttu-id="d03ae-223">Para obter mais informações sobre esse algoritmo, consulte [Microsoft Time Series Algorithm Technical Reference](microsoft-time-series-algorithm-technical-reference.md).</span><span class="sxs-lookup"><span data-stu-id="d03ae-223">For more information about this algorithm, see [Microsoft Time Series Algorithm Technical Reference](microsoft-time-series-algorithm-technical-reference.md).</span></span>|  
  
## <a name="feature-selection-parameters"></a><span data-ttu-id="d03ae-224">Parâmetros de seleção de recursos</span><span class="sxs-lookup"><span data-stu-id="d03ae-224">Feature Selection Parameters</span></span>  
 <span data-ttu-id="d03ae-225">Nos algoritmos que suportam a seleção de recursos, é possível controlar quando a seleção de recursos é ativada usando os parâmetros a seguir.</span><span class="sxs-lookup"><span data-stu-id="d03ae-225">In algorithms that support feature selection, you can control when feature selection is turned on by using the following parameters.</span></span> <span data-ttu-id="d03ae-226">Cada algoritmo tem um valor padrão para o número de entradas permitidas, mas você pode substituir esse padrão e especificar o número de atributos.</span><span class="sxs-lookup"><span data-stu-id="d03ae-226">Each algorithm has a default value for the number of inputs that are allowed, but you can override this default and specify the number of attributes.</span></span> <span data-ttu-id="d03ae-227">Esta seção lista os parâmetros que são fornecidos para gerenciar a seleção de recursos.</span><span class="sxs-lookup"><span data-stu-id="d03ae-227">This section lists the parameters that are provided for managing feature selection.</span></span>  
  
#### <a name="maximum_input_attributes"></a><span data-ttu-id="d03ae-228">MAXIMUM_INPUT_ATTRIBUTES</span><span class="sxs-lookup"><span data-stu-id="d03ae-228">MAXIMUM_INPUT_ATTRIBUTES</span></span>  
 <span data-ttu-id="d03ae-229">Se o modelo tiver mais colunas do que o número especificado no parâmetro *MAXIMUM_INPUT_ATTRIBUTES* , o algoritmo ignorará as colunas calculadas como não interessantes.</span><span class="sxs-lookup"><span data-stu-id="d03ae-229">If a model contains more columns than the number that is specified in the *MAXIMUM_INPUT_ATTRIBUTES* parameter, the algorithm ignores any columns that it calculates to be uninteresting.</span></span>  
  
#### <a name="maximum_output_attributes"></a><span data-ttu-id="d03ae-230">MAXIMUM_OUTPUT_ATTRIBUTES</span><span class="sxs-lookup"><span data-stu-id="d03ae-230">MAXIMUM_OUTPUT_ATTRIBUTES</span></span>  
 <span data-ttu-id="d03ae-231">Da mesma forma, se o modelo tiver mais colunas previsíveis do que o número especificado no parâmetro *MAXIMUM_OUTPUT_ATTRIBUTES* , o algoritmo ignorará as colunas calculadas como não interessantes.</span><span class="sxs-lookup"><span data-stu-id="d03ae-231">Similarly, if a model contains more predictable columns than the number that is specified in the *MAXIMUM_OUTPUT_ATTRIBUTES* parameter, the algorithm ignores any columns that it calculates to be uninteresting.</span></span>  
  
#### <a name="maximum_states"></a><span data-ttu-id="d03ae-232">MAXIMUM_STATES</span><span class="sxs-lookup"><span data-stu-id="d03ae-232">MAXIMUM_STATES</span></span>  
 <span data-ttu-id="d03ae-233">Se um modelo tiver mais casos que os especificado no parâmetro *MAXIMUM_STATES* , os estados menos populares serão agrupados para tratados como ausentes.</span><span class="sxs-lookup"><span data-stu-id="d03ae-233">If a model contains more cases than are specified in the *MAXIMUM_STATES* parameter, the least popular states are grouped together and treated as missing.</span></span> <span data-ttu-id="d03ae-234">Se qualquer um desses parâmetros for definido como 0, a seleção de recursos será desativada, o que afeta o tempo de processamento e o desempenho.</span><span class="sxs-lookup"><span data-stu-id="d03ae-234">If any one of these parameters is set to 0, feature selection is turned off, affecting processing time and performance.</span></span>  
  
 <span data-ttu-id="d03ae-235">Além destes métodos para seleção de recursos, você pode melhorar a capacidade de o algoritmo identificar ou promover atributos significativos definindo *sinalizadores de modelagem* no modelo ou definindo *sinalizadores de distribuição* na estrutura.</span><span class="sxs-lookup"><span data-stu-id="d03ae-235">In addition to these methods for feature selection, you can improve the ability of the algorithm to identify or promote meaningful attributes by setting *modeling flags* on the model or by setting *distribution flags* on the structure.</span></span> <span data-ttu-id="d03ae-236">Para obter mais informações sobre esses conceitos, consulte [Sinalizadores de modelagem &#40;Data Mining&#41;](modeling-flags-data-mining.md) e [Distribuições de colunas &#40;Data Mining&#41;](column-distributions-data-mining.md).</span><span class="sxs-lookup"><span data-stu-id="d03ae-236">For more information about these concepts, see [Modeling Flags &#40;Data Mining&#41;](modeling-flags-data-mining.md) and [Column Distributions &#40;Data Mining&#41;](column-distributions-data-mining.md).</span></span>  
  
## <a name="see-also"></a><span data-ttu-id="d03ae-237">Consulte Também</span><span class="sxs-lookup"><span data-stu-id="d03ae-237">See Also</span></span>  
 [<span data-ttu-id="d03ae-238">Personalizar os modelos de mineração e a estrutura</span><span class="sxs-lookup"><span data-stu-id="d03ae-238">Customize Mining Models and Structure</span></span>](customize-mining-models-and-structure.md)  
  
  
