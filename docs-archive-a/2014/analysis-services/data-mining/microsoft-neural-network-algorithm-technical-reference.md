---
title: Referência técnica do algoritmo rede neural da Microsoft | Microsoft Docs
ms.custom: ''
ms.date: 06/13/2017
ms.prod: sql-server-2014
ms.reviewer: ''
ms.technology: analysis-services
ms.topic: conceptual
helpviewer_keywords:
- HIDDEN_NODE_RATIO parameter
- MAXIMUM_INPUT_ATTRIBUTES parameter
- HOLDOUT_PERCENTAGE parameter
- neural network algorithms [Analysis Services]
- output layer [Data Mining]
- neural networks
- MAXIMUM_OUTPUT_ATTRIBUTES parameter
- MAXIMUM_STATES parameter
- SAMPLE_SIZE parameter
- hidden layer
- hidden neurons
- input layer [Data Mining]
- activation function [Data Mining]
- Back-Propagated Delta Rule network
- neural network model [Analysis Services]
- coding [Data Mining]
- HOLDOUT_SEED parameter
ms.assetid: b8fac409-e3c0-4216-b032-364f8ea51095
author: minewiskan
ms.author: owend
ms.openlocfilehash: 3c36fd9f3446ddf36da9af7ce58259edbe84c8cf
ms.sourcegitcommit: ad4d92dce894592a259721a1571b1d8736abacdb
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 08/04/2020
ms.locfileid: "87568902"
---
# <a name="microsoft-neural-network-algorithm-technical-reference"></a><span data-ttu-id="a05a7-102">Microsoft Neural Network Algorithm Technical Reference</span><span class="sxs-lookup"><span data-stu-id="a05a7-102">Microsoft Neural Network Algorithm Technical Reference</span></span>
  <span data-ttu-id="a05a7-103">A Rede Neural da [!INCLUDE[msCoName](../../includes/msconame-md.md)] usa uma rede *multicamadas Perceptron* , também denominada *rede Regra-Delta com Algoritmo Backpropagation*, composta de até três camadas de neurônios ou *perceptrons*.</span><span class="sxs-lookup"><span data-stu-id="a05a7-103">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Neural Network uses a *Multilayer Perceptron* network, also called a *Back-Propagated Delta Rule network*, composed of up to three layers of neurons, or *perceptrons*.</span></span> <span data-ttu-id="a05a7-104">Essas camadas são uma camada de entrada, uma camada opcional oculta e uma camada de saída.</span><span class="sxs-lookup"><span data-stu-id="a05a7-104">These layers are an input layer, an optional hidden layer, and an output layer.</span></span>  
  
 <span data-ttu-id="a05a7-105">Uma descrição detalhada das redes neurais de multicamadas Perceptron está fora do escopo da presente documentação.</span><span class="sxs-lookup"><span data-stu-id="a05a7-105">A detailed discussion of Multilayer Perceptron neural networks is outside the scope of this documentation.</span></span> <span data-ttu-id="a05a7-106">Este tópico explica a implementação básica do algoritmo, incluindo o método usado para normalizar valores de entrada e saída, e os métodos de seleção de recursos utilizados para reduzir a cardinalidade do atributo.</span><span class="sxs-lookup"><span data-stu-id="a05a7-106">This topic explains the basic implementation of the algorithm, including the method used to normalize input and output values, and feature selection methods used to reduce attribute cardinality.</span></span> <span data-ttu-id="a05a7-107">Este tópico descreve os parâmetros e outras configurações que podem ser usadas para personalizar o comportamento do algoritmo, além de fornecer links para informações adicionais sobre como consultar o modelo.</span><span class="sxs-lookup"><span data-stu-id="a05a7-107">This topic describes the parameters and other settings that can be used to customize the behavior of the algorithm, and provides links to additional information about querying the model.</span></span>  
  
## <a name="implementation-of-the-microsoft-neural-network-algorithm"></a><span data-ttu-id="a05a7-108">Implementação do algoritmo Rede Neural da Microsoft</span><span class="sxs-lookup"><span data-stu-id="a05a7-108">Implementation of the Microsoft Neural Network Algorithm</span></span>  
 <span data-ttu-id="a05a7-109">Em uma rede neural multicamadas Perceptron, cada neurônio recebe uma ou mais entradas e produz uma ou mais saídas idênticas.</span><span class="sxs-lookup"><span data-stu-id="a05a7-109">In a Multilayer Perceptron neural network, each neuron receives one or more inputs and produces one or more identical outputs.</span></span> <span data-ttu-id="a05a7-110">Cada saída é uma função não linear simples da soma das entradas ao neurônio.</span><span class="sxs-lookup"><span data-stu-id="a05a7-110">Each output is a simple non-linear function of the sum of the inputs to the neuron.</span></span> <span data-ttu-id="a05a7-111">As entradas só passam para frente a partir de nós na camada de entrada até nós na camada oculta, e passam da camada oculta para a camada de saída sem nenhuma conexão entre os neurônios na camada.</span><span class="sxs-lookup"><span data-stu-id="a05a7-111">Inputs pass forward from nodes in the input layer to nodes in the hidden layer, and then pass from the hidden layer to the output layer; there are no connections between neurons within a layer.</span></span> <span data-ttu-id="a05a7-112">Se não houver nenhuma camada oculta, como no modelo de regressão logística, as entradas passarão diretamente dos nós na camada de entrada para os nós na camada de saída.</span><span class="sxs-lookup"><span data-stu-id="a05a7-112">If no hidden layer is included, as in a logistic regression model, inputs pass forward directly from nodes in the input layer to nodes in the output layer.</span></span>  
  
 <span data-ttu-id="a05a7-113">Há três tipos de neurônios em uma rede neural que é criada com o algoritmo Rede Neural da [!INCLUDE[msCoName](../../includes/msconame-md.md)] :</span><span class="sxs-lookup"><span data-stu-id="a05a7-113">There are three types of neurons in a neural network that is created with the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Neural Network algorithm:</span></span>  
  
-   `Input neurons`  
  
 <span data-ttu-id="a05a7-114">Neurônios de entrada fornecem valores de atributo de entrada para o modelo de mineração de dados.</span><span class="sxs-lookup"><span data-stu-id="a05a7-114">Input neurons provide input attribute values for the data mining model.</span></span> <span data-ttu-id="a05a7-115">Para atributos de entrada discretos, um neurônio de entrada representa normalmente um único estado do atributo de entrada.</span><span class="sxs-lookup"><span data-stu-id="a05a7-115">For discrete input attributes, an input neuron typically represents a single state from the input attribute.</span></span> <span data-ttu-id="a05a7-116">Isso incluirá valores ausentes, se os dados de treinamento contiverem nulos para esse atributo.</span><span class="sxs-lookup"><span data-stu-id="a05a7-116">This includes missing values, if the training data contains nulls for that attribute.</span></span> <span data-ttu-id="a05a7-117">Um atributo de entrada discreto que tiver mais de dois estados gerará um neurônio de entrada para cada estado e um neurônio de entrada para o estado existente ou ausente, se houver nulos nos dados de treinamento.</span><span class="sxs-lookup"><span data-stu-id="a05a7-117">A discrete input attribute that has more than two states generates one input neuron for each state, and one input neuron for a missing state, if there are any nulls in the training data.</span></span> <span data-ttu-id="a05a7-118">Um atributo de entrada contínuo gera dois neurônios de entrada: um para um estado ausente, e um para o valor do próprio atributo contínuo.</span><span class="sxs-lookup"><span data-stu-id="a05a7-118">A continuous input attribute generates two input neurons: one neuron for a missing state, and one neuron for the value of the continuous attribute itself.</span></span> <span data-ttu-id="a05a7-119">Os neurônios de entrada fornecem entradas para um ou mais neurônios ocultos.</span><span class="sxs-lookup"><span data-stu-id="a05a7-119">Input neurons provide inputs to one or more hidden neurons.</span></span>  
  
-   `Hidden neurons`  
  
 <span data-ttu-id="a05a7-120">Neurônios ocultos recebem entradas de neurônios de entrada e fornecem saídas para os neurônios de saída.</span><span class="sxs-lookup"><span data-stu-id="a05a7-120">Hidden neurons receive inputs from input neurons and provide outputs to output neurons.</span></span>  
  
-   `Output neurons`  
  
 <span data-ttu-id="a05a7-121">Os neurônios de saída representam valores de atributos previsíveis para o modelo de mineração de dados.</span><span class="sxs-lookup"><span data-stu-id="a05a7-121">Output neurons represent predictable attribute values for the data mining model.</span></span> <span data-ttu-id="a05a7-122">Para atributos de entrada discretos, um neurônio de saída representa normalmente um único estado previsto para um atributo previsível, inclusive valores ausentes.</span><span class="sxs-lookup"><span data-stu-id="a05a7-122">For discrete input attributes, an output neuron typically represents a single predicted state for a predictable attribute, including missing values.</span></span> <span data-ttu-id="a05a7-123">Por exemplo, um atributo previsível binário produz um nó de saída que descreve um estado existente ou ausente, para indicar se existe um valor para aquele atributo.</span><span class="sxs-lookup"><span data-stu-id="a05a7-123">For example, a binary predictable attribute produces one output node that describes a missing or existing state, to indicate whether a value exists for that attribute.</span></span> <span data-ttu-id="a05a7-124">Uma coluna booliana usada como atributo previsível gera três neurônios de saída: um para um valor verdadeiro, um para um valor falso e um para um estado existente ou ausente.</span><span class="sxs-lookup"><span data-stu-id="a05a7-124">A Boolean column that is used as a predictable attribute generates three output neurons: one neuron for a true value, one neuron for a false value, and one neuron for a missing or existing state.</span></span> <span data-ttu-id="a05a7-125">Um atributo predicável discreto que tiver mais de dois estados gerará um neurônio de saída para cada estado e um neurônio de saída para o estado existente ou ausente.</span><span class="sxs-lookup"><span data-stu-id="a05a7-125">A discrete predictable attribute that has more than two states generates one output neuron for each state, and one output neuron for a missing or existing state.</span></span> <span data-ttu-id="a05a7-126">Colunas previsíveis contínuas geram dois neurônios de saída: um para um estado existente ou ausente e um para o valor do próprio atributo contínuo.</span><span class="sxs-lookup"><span data-stu-id="a05a7-126">Continuous predictable columns generate two output neurons: one neuron for a missing or existing state, and one neuron for the value of the continuous column itself.</span></span> <span data-ttu-id="a05a7-127">Se mais de 500 neurônios de saída forem gerados por meio da revisão do conjunto de colunas previsíveis, o [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] gerará uma nova rede no modelo de mineração para representar os neurônios de saída adicionais.</span><span class="sxs-lookup"><span data-stu-id="a05a7-127">If more than 500 output neurons are generated by reviewing the set of predictable columns, [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] generates a new network in the mining model to represent the additional output neurons.</span></span>  
  
 <span data-ttu-id="a05a7-128">Um neurônio recebe entrada de outros neurônios ou de outros dados, dependendo de qual camada da rede ele está.</span><span class="sxs-lookup"><span data-stu-id="a05a7-128">A neuron receives input from other neurons, or from other data, depending on which layer of the network it is in.</span></span> <span data-ttu-id="a05a7-129">Um neurônio de entrada recebe entradas dos dados originais.</span><span class="sxs-lookup"><span data-stu-id="a05a7-129">An input neuron receives inputs from the original data.</span></span> <span data-ttu-id="a05a7-130">Os neurônios ocultos e os neurônios de saída recebem entradas da saída de outros neurônios na rede neural.</span><span class="sxs-lookup"><span data-stu-id="a05a7-130">Hidden neurons and output neurons receive inputs from the output of other neurons in the neural network.</span></span> <span data-ttu-id="a05a7-131">As entradas estabelecem relações entre neurônios e as relações servem como caminho de análise para um conjunto específico de casos.</span><span class="sxs-lookup"><span data-stu-id="a05a7-131">Inputs establish relationships between neurons, and the relationships serve as a path of analysis for a specific set of cases.</span></span>  
  
 <span data-ttu-id="a05a7-132">Cada entrada tem um valor atribuído a ele, denominado *peso*, que descreve a relevância ou a importância de uma entrada específica para um neurônio oculto ou para um neurônio de saída.</span><span class="sxs-lookup"><span data-stu-id="a05a7-132">Each input has a value assigned to it, called the *weight*, which describes the relevance or importance of that particular input to the hidden neuron or the output neuron.</span></span> <span data-ttu-id="a05a7-133">Quanto maior o peso atribuído a uma entrada, mais relevante ou importante será o valor dessa entrada.</span><span class="sxs-lookup"><span data-stu-id="a05a7-133">The greater the weight that is assigned to an input, the more relevant or important the value of that input.</span></span> <span data-ttu-id="a05a7-134">Os pesos podem ser negativos, o que implica que a entrada pode inibir, em vez de ativar, um neurônio específico.</span><span class="sxs-lookup"><span data-stu-id="a05a7-134">Weights can be negative, which implies that the input can inhibit, rather than activate, a specific neuron.</span></span> <span data-ttu-id="a05a7-135">O valor de cada entrada é multiplicado pelo peso para enfatizar a importância de uma entrada para um determinado neurônio.</span><span class="sxs-lookup"><span data-stu-id="a05a7-135">The value of each input is multiplied by the weight to emphasize the importance of an input for a specific neuron.</span></span> <span data-ttu-id="a05a7-136">Para pesos negativos, o efeito de multiplicar o valor pelo peso é remover a importância.</span><span class="sxs-lookup"><span data-stu-id="a05a7-136">For negative weights, the effect of multiplying the value by the weight is to deemphasize the importance.</span></span>  
  
 <span data-ttu-id="a05a7-137">Cada neurônio tem atribuído a ele uma função não linear simples, denominada *função de ativação*, que descreve a relevância ou a importância de um neurônio específico para a camada da rede neural.</span><span class="sxs-lookup"><span data-stu-id="a05a7-137">Each neuron has a simple non-linear function assigned to it, called the *activation function*, which describes the relevance or importance of a particular neuron to that layer of a neural network.</span></span> <span data-ttu-id="a05a7-138">Neurônios ocultos usam uma função *tangente hiperbólica* (tanh) como sua função de ativação, enquanto os neurônios de saída utilizam uma função *sigmoide* para ativação.</span><span class="sxs-lookup"><span data-stu-id="a05a7-138">Hidden neurons use a *hyperbolic tangent* function (tanh) for their activation function, whereas output neurons use a *sigmoid* function for activation.</span></span> <span data-ttu-id="a05a7-139">Ambas as funções, são funções não lineares, contínuas e que fazem com que a rede neural modele relações não lineares entre os neurônios de entrada e de saída.</span><span class="sxs-lookup"><span data-stu-id="a05a7-139">Both functions are nonlinear, continuous functions that allow the neural network to model nonlinear relationships between input and output neurons.</span></span>  
  
### <a name="training-neural-networks"></a><span data-ttu-id="a05a7-140">Treinando Redes Neurais</span><span class="sxs-lookup"><span data-stu-id="a05a7-140">Training Neural Networks</span></span>  
 <span data-ttu-id="a05a7-141">Várias etapas são envolvidas no treinamento de um modelo de mineração de dados que usa o algoritmo Rede Neural da [!INCLUDE[msCoName](../../includes/msconame-md.md)] .</span><span class="sxs-lookup"><span data-stu-id="a05a7-141">Several steps are involved in training a data mining model that uses the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Neural Network algorithm.</span></span> <span data-ttu-id="a05a7-142">Essas etapas são amplamente influenciadas pelos valores especificados para os parâmetros do algoritmo.</span><span class="sxs-lookup"><span data-stu-id="a05a7-142">These steps are heavily influenced by the values that you specify for the algorithm parameters.</span></span>  
  
 <span data-ttu-id="a05a7-143">O algoritmo primeiro avalia e depois extrai dados de treinamento da fonte de dados.</span><span class="sxs-lookup"><span data-stu-id="a05a7-143">The algorithm first evaluates and extracts training data from the data source.</span></span> <span data-ttu-id="a05a7-144">A porcentagem dos dados de treinamento, chamados *dados de validação*, é reservada para o uso na avaliação da precisão da rede.</span><span class="sxs-lookup"><span data-stu-id="a05a7-144">A percentage of the training data, called the *holdout data*, is reserved for use in assessing the accuracy of the network.</span></span> <span data-ttu-id="a05a7-145">Durante o processo de treinamento, a rede é avaliada imediatamente após cada iteração pelos dados de treinamento.</span><span class="sxs-lookup"><span data-stu-id="a05a7-145">Throughout the training process, the network is evaluated immediately after each iteration through the training data.</span></span> <span data-ttu-id="a05a7-146">Quando a precisão não aumentar mais, o processo de treinamento será interrompido.</span><span class="sxs-lookup"><span data-stu-id="a05a7-146">When the accuracy no longer increases, the training process is stopped.</span></span>  
  
 <span data-ttu-id="a05a7-147">Os valores dos parâmetros *SAMPLE_SIZE* e *HOLDOUT_PERCENTAGE* são usados para definir o número de casos a serem amostrados dos dados de treinamento e o número de casos a serem deixados de lado para os dados de controle.</span><span class="sxs-lookup"><span data-stu-id="a05a7-147">The values of the *SAMPLE_SIZE* and *HOLDOUT_PERCENTAGE* parameters are used to determine the number of cases to sample from the training data and the number of cases to be put aside for the holdout data.</span></span> <span data-ttu-id="a05a7-148">O valor do parâmetro *HOLDOUT_SEED* é usado para definir aleatoriamente os casos individuais a serem deixados de lado para os dados de controle.</span><span class="sxs-lookup"><span data-stu-id="a05a7-148">The value of the *HOLDOUT_SEED* parameter is used to randomly determine the individual cases to be put aside for the holdout data.</span></span>  
  
> [!NOTE]  
>  <span data-ttu-id="a05a7-149">Esses parâmetros de algoritmo são diferentes das propriedades HOLDOUT_SIZE e HOLDOUT_SEED, que são aplicadas a uma estrutura de mineração para definir um conjunto de dados de teste.</span><span class="sxs-lookup"><span data-stu-id="a05a7-149">These algorithm parameters are different from the HOLDOUT_SIZE and HOLDOUT_SEED properties, which are applied to a mining structure to define a testing data set.</span></span>  
  
 <span data-ttu-id="a05a7-150">O algoritmo seguinte define o número e a complexidade das redes que o modelo de mineração tem suporte.</span><span class="sxs-lookup"><span data-stu-id="a05a7-150">The algorithm next determines the number and complexity of the networks that the mining model supports.</span></span> <span data-ttu-id="a05a7-151">Se o modelo de mineração contém um ou mais atributos usados apenas para previsão, o algoritmo cria uma única rede que representa todos esses atributos.</span><span class="sxs-lookup"><span data-stu-id="a05a7-151">If the mining model contains one or more attributes that are used only for prediction, the algorithm creates a single network that represents all such attributes.</span></span> <span data-ttu-id="a05a7-152">Se o modelo de mineração contém um ou mais atributos usados para entrada e previsão, o provedor do algoritmo construirá uma rede para cada atributo.</span><span class="sxs-lookup"><span data-stu-id="a05a7-152">If the mining model contains one or more attributes that are used for both input and prediction, the algorithm provider constructs a network for each attribute.</span></span>  
  
 <span data-ttu-id="a05a7-153">Para atributos de entrada e previsíveis com valores discretos, cada neurônio de entrada ou de saída representa respectivamente um único estado.</span><span class="sxs-lookup"><span data-stu-id="a05a7-153">For input and predictable attributes that have discrete values, each input or output neuron respectively represents a single state.</span></span> <span data-ttu-id="a05a7-154">Para atributos de entrada e previsíveis com valores contínuos, cada neurônio de entrada ou de saída representa respectivamente o intervalo e a distribuição de valores para o atributo.</span><span class="sxs-lookup"><span data-stu-id="a05a7-154">For input and predictable attributes that have continuous values, each input or output neuron respectively represents the range and distribution of values for the attribute.</span></span> <span data-ttu-id="a05a7-155">O número máximo de estados com suporte em ambos os casos depende do valor do parâmetro do algoritmo *MAXIMUM_STATES* .</span><span class="sxs-lookup"><span data-stu-id="a05a7-155">The maximum number of states that is supported in either case depends on the value of the *MAXIMUM_STATES* algorithm parameter.</span></span> <span data-ttu-id="a05a7-156">Se o número de estados para um atributo específico exceder o valor do parâmetro do algoritmo *MAXIMUM_STATES* , os estados mais populares ou relevantes para esse atributo serão escolhidos, até o máximo de estados permitidos, e os demais estados serão agrupados como valores ausentes para efeito de análise.</span><span class="sxs-lookup"><span data-stu-id="a05a7-156">If the number of states for a specific attribute exceeds the value of the *MAXIMUM_STATES* algorithm parameter, the most popular or relevant states for that attribute are chosen, up to the maximum number of states allowed, and the remaining states are grouped as missing values for the purposes of analysis.</span></span>  
  
 <span data-ttu-id="a05a7-157">Então, o algoritmo usará o valor do parâmetro *HIDDEN_NODE_RATIO* quando for determinar o número inicial de neurônios a serem criados para a camada oculta.</span><span class="sxs-lookup"><span data-stu-id="a05a7-157">The algorithm then uses the value of the *HIDDEN_NODE_RATIO* parameter when determining the initial number of neurons to create for the hidden layer.</span></span> <span data-ttu-id="a05a7-158">Você pode definir *HIDDEN_NODE_RATIO* como 0 para impedir a criação de camada oculta nas redes que o algoritmo gera para o modelo de mineração, a fim de tratar a rede neural como uma regressão lógica.</span><span class="sxs-lookup"><span data-stu-id="a05a7-158">You can set *HIDDEN_NODE_RATIO* to 0 to prevent the creation of a hidden layer in the networks that the algorithm generates for the mining model, to treat the neural network as a logistic regression.</span></span>  
  
 <span data-ttu-id="a05a7-159">O provedor de algoritmos avalia iterativamente o peso de todas as entradas na rede ao mesmo tempo, selecionando o conjunto de dados de treinamento que foi reservado anteriormente e, comparando o valor atual conhecido de cada caso nos dados de validação com a previsão da rede em um processo definido como *aprendizado em lotes*.</span><span class="sxs-lookup"><span data-stu-id="a05a7-159">The algorithm provider iteratively evaluates the weight for all inputs across the network at the same time, by taking the set of training data that was reserved earlier and comparing the actual known value for each case in the holdout data with the network's prediction, in a process known as *batch learning*.</span></span> <span data-ttu-id="a05a7-160">Após o algoritmo avaliar o conjunto inteiro dos dados de treinamento, ele revisa o valor atual e previsto para cada neurônio.</span><span class="sxs-lookup"><span data-stu-id="a05a7-160">After the algorithm has evaluated the entire set of training data, the algorithm reviews the predicted and actual value for each neuron.</span></span> <span data-ttu-id="a05a7-161">O algoritmo calcula o grau do erro, se houver, e ajusta os pesos associados com as entradas daquele neurônio, funcionando em direção oposta, dos neurônios de saída para os neurônios de entrada, em um processo conhecimento como *backpropagation*.</span><span class="sxs-lookup"><span data-stu-id="a05a7-161">The algorithm calculates the degree of error, if any, and adjusts the weights that are associated with the inputs for that neuron, working backward from output neurons to input neurons in a process known as *backpropagation*.</span></span> <span data-ttu-id="a05a7-162">O algoritmo repete então o processo em todo o conjunto dos dados de treinamento.</span><span class="sxs-lookup"><span data-stu-id="a05a7-162">The algorithm then repeats the process over the entire set of training data.</span></span> <span data-ttu-id="a05a7-163">Devido ao fato do algoritmo ter suporte para vários pesos e neurônios de saída, o algoritmo gradiente conjugado é usado para guiar o processo de treinamento a fim de atribuir e avaliar os pesos para as entradas.</span><span class="sxs-lookup"><span data-stu-id="a05a7-163">Because the algorithm can support many weights and output neurons, the conjugate gradient algorithm is used to guide the training process for assigning and evaluating weights for inputs.</span></span> <span data-ttu-id="a05a7-164">Uma descrição do algoritmo gradiente conjugado está fora do escopo desta documentação.</span><span class="sxs-lookup"><span data-stu-id="a05a7-164">A discussion of the conjugate gradient algorithm is outside the scope of this documentation.</span></span>  
  
### <a name="feature-selection"></a><span data-ttu-id="a05a7-165">Seleção de recursos</span><span class="sxs-lookup"><span data-stu-id="a05a7-165">Feature Selection</span></span>  
 <span data-ttu-id="a05a7-166">Se o número de atributos de entrada for maior do que o valor do parâmetro *MAXIMUM_INPUT_ATTRIBUTES* ou se o número de atributos previsíveis for maior do que o valor do parâmetro *MAXIMUM_OUTPUT_ATTRIBUTES* , um algoritmo de seleção de recursos será usado para reduzir a complexidade das redes incluídas no modelo de mineração.</span><span class="sxs-lookup"><span data-stu-id="a05a7-166">If the number of input attributes is greater than the value of the *MAXIMUM_INPUT_ATTRIBUTES* parameter, or if the number of predictable attributes is greater than the value of the *MAXIMUM_OUTPUT_ATTRIBUTES* parameter, a feature selection algorithm is used to reduce the complexity of the networks that are included in the mining model.</span></span> <span data-ttu-id="a05a7-167">A seleção de recursos reduz o número de atributos de entrada e previsíveis para deixar apenas aqueles que são estatisticamente relevantes para o modelo.</span><span class="sxs-lookup"><span data-stu-id="a05a7-167">Feature selection reduces the number of input or predictable attributes to those that are most statistically relevant to the model.</span></span>  
  
 <span data-ttu-id="a05a7-168">A seleção de recursos é usada automaticamente por todos os algoritmos de mineração de dados [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] para melhorar a análise e reduzir a carga de processamento.</span><span class="sxs-lookup"><span data-stu-id="a05a7-168">Feature selection is used automatically by all [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] data mining algorithms to improve analysis and reduce processing load.</span></span> <span data-ttu-id="a05a7-169">O método usado para seleção de recursos em modelos de rede neural depende do tipo de dados do atributo.</span><span class="sxs-lookup"><span data-stu-id="a05a7-169">The method used for feature selection in neural network models depends on the data type of the attribute.</span></span> <span data-ttu-id="a05a7-170">Para referência, a tabela a seguir mostra os métodos de seleção de recursos usados para modelos de rede neural e os métodos de seleção de recursos usados para o algoritmo de Regressão Logística, que se baseia no algoritmo Rede Neural.</span><span class="sxs-lookup"><span data-stu-id="a05a7-170">For reference, the following table shows the feature selection methods used for neural network models, and also shows the feature selection methods used for the Logistic Regression algorithm, which is based on the Neural Network algorithm.</span></span>  
  
|<span data-ttu-id="a05a7-171">Algoritmo</span><span class="sxs-lookup"><span data-stu-id="a05a7-171">Algorithm</span></span>|<span data-ttu-id="a05a7-172">Método de análise</span><span class="sxs-lookup"><span data-stu-id="a05a7-172">Method of analysis</span></span>|<span data-ttu-id="a05a7-173">Comentários</span><span class="sxs-lookup"><span data-stu-id="a05a7-173">Comments</span></span>|  
|---------------|------------------------|--------------|  
|<span data-ttu-id="a05a7-174">Rede Neural</span><span class="sxs-lookup"><span data-stu-id="a05a7-174">Neural Network</span></span>|<span data-ttu-id="a05a7-175">Pontuação de interesse</span><span class="sxs-lookup"><span data-stu-id="a05a7-175">Interestingness score</span></span><br /><br /> <span data-ttu-id="a05a7-176">Entropia de Shannon</span><span class="sxs-lookup"><span data-stu-id="a05a7-176">Shannon's Entropy</span></span><br /><br /> <span data-ttu-id="a05a7-177">Bayesian com K2 a priori</span><span class="sxs-lookup"><span data-stu-id="a05a7-177">Bayesian with K2 Prior</span></span><br /><br /> <span data-ttu-id="a05a7-178">Bayesian Dirichlet com uniforme a priori (padrão)</span><span class="sxs-lookup"><span data-stu-id="a05a7-178">Bayesian Dirichlet with uniform prior (default)</span></span>|<span data-ttu-id="a05a7-179">O algoritmo Redes Neurais pode usar ambos os métodos de pontuação Bayesiano e baseado em entropia, desde que os dados contenham colunas contínuas.</span><span class="sxs-lookup"><span data-stu-id="a05a7-179">The Neural Networks algorithm can use both entropy-based and Bayesian scoring methods, as long as the data contains continuous columns.</span></span><br /><br /> <span data-ttu-id="a05a7-180">Padrão.</span><span class="sxs-lookup"><span data-stu-id="a05a7-180">Default.</span></span>|  
|<span data-ttu-id="a05a7-181">Regressão Logística</span><span class="sxs-lookup"><span data-stu-id="a05a7-181">Logistic Regression</span></span>|<span data-ttu-id="a05a7-182">Pontuação de interesse</span><span class="sxs-lookup"><span data-stu-id="a05a7-182">Interestingness score</span></span><br /><br /> <span data-ttu-id="a05a7-183">Entropia de Shannon</span><span class="sxs-lookup"><span data-stu-id="a05a7-183">Shannon's Entropy</span></span><br /><br /> <span data-ttu-id="a05a7-184">Bayesian com K2 a priori</span><span class="sxs-lookup"><span data-stu-id="a05a7-184">Bayesian with K2 Prior</span></span><br /><br /> <span data-ttu-id="a05a7-185">Bayesian Dirichlet com uniforme a priori (padrão)</span><span class="sxs-lookup"><span data-stu-id="a05a7-185">Bayesian Dirichlet with uniform prior (default)</span></span>|<span data-ttu-id="a05a7-186">Como não é possível indicar um parâmetro para esse algoritmo controlar o comportamento de seleção de recursos, os padrões são usados.</span><span class="sxs-lookup"><span data-stu-id="a05a7-186">Because you cannot pass a parameter to this algorithm to control feature election behavior, the defaults are used.</span></span> <span data-ttu-id="a05a7-187">Sendo assim, se todos os atributos forem discretos ou diferenciados, o padrão será BDEU.</span><span class="sxs-lookup"><span data-stu-id="a05a7-187">Therefore, if all attributes are discrete or discretized, the default is BDEU.</span></span>|  
  
 <span data-ttu-id="a05a7-188">Os parâmetros de algoritmo que controlam a seleção de recursos para um modelo de rede neural são MAXIMUM_INPUT_ATTRIBUTES, MAXIMUM_OUTPUT_ATTRIBUTES e MAXIMUM_STATES.</span><span class="sxs-lookup"><span data-stu-id="a05a7-188">The algorithm parameters that control feature selection for a neural network model are MAXIMUM_INPUT_ATTRIBUTES, MAXIMUM_OUTPUT_ATTRIBUTES, and MAXIMUM_STATES.</span></span> <span data-ttu-id="a05a7-189">Você também pode controlar o número de camadas ocultas definindo o parâmetro HIDDEN_NODE_RATIO.</span><span class="sxs-lookup"><span data-stu-id="a05a7-189">You can also control the number of hidden layers by setting the HIDDEN_NODE_RATIO parameter.</span></span>  
  
### <a name="scoring-methods"></a><span data-ttu-id="a05a7-190">Métodos de pontuação</span><span class="sxs-lookup"><span data-stu-id="a05a7-190">Scoring Methods</span></span>  
 <span data-ttu-id="a05a7-191">A*Pontuação* é um tipo de normalização que, no contexto de treinamento de um modelo de rede neural, significa o processo de converter um valor, como uma etiqueta de texto discreta, em um valor que possa ser comparado com outros tipos de entradas e ponderado na rede.</span><span class="sxs-lookup"><span data-stu-id="a05a7-191">*Scoring* is a kind of normalization, which in the context of training a neural network model means the process of converting a value, such as a discrete text label, into a value that can be compared with other types of inputs and weighted in the network.</span></span> <span data-ttu-id="a05a7-192">Por exemplo, se um atributo de entrada for Sexo e os valores possíveis forem Masculino e Feminino, e outro atributo de entrada for Renda, com um intervalo variável de valores, os valores de cada atributo não serão diretamente comparáveis e, portanto, deverão ser codificados para uma escala comum para que os pesos possam ser calculados.</span><span class="sxs-lookup"><span data-stu-id="a05a7-192">For example, if one input attribute is Gender and the possible values are Male and Female, and another input attribute is Income, with a variable range of values, the values for each attribute are not directly comparable, and therefore must be encoded to a common scale so that the weights can be computed.</span></span> <span data-ttu-id="a05a7-193">A pontuação é o processo de normalizar essas entradas para valores numéricos: especificamente para um intervalo de probabilidade.</span><span class="sxs-lookup"><span data-stu-id="a05a7-193">Scoring is the process of normalizing such inputs to numeric values: specifically, to a probability range.</span></span> <span data-ttu-id="a05a7-194">As funções usadas para normalização também ajudam a distribuir o valor de entrada mais uniformemente em uma escala uniforme, para que valores extremos não distorçam os resultados da análise.</span><span class="sxs-lookup"><span data-stu-id="a05a7-194">The functions used for normalization also help to distribute input value more evenly on a uniform scale so that extreme values do not distort the results of analysis.</span></span>  
  
 <span data-ttu-id="a05a7-195">As saídas da rede neural também são codificadas.</span><span class="sxs-lookup"><span data-stu-id="a05a7-195">Outputs of the neural network are also encoded.</span></span> <span data-ttu-id="a05a7-196">Quando há um único destino para a saída (isto é, previsão), ou vários destinos que são usados apenas para previsão e não para entrada, o modelo cria uma única rede e talvez não seja necessário para normalizar os valores.</span><span class="sxs-lookup"><span data-stu-id="a05a7-196">When there is a single target for output (that is, prediction), or multiple targets that are used for prediction only and not for input, the model create a single network and it might not seem necessary to normalize the values.</span></span> <span data-ttu-id="a05a7-197">No entanto, se vários atributos forem usados para entrada e previsão, o modelo deverá criar várias redes; portanto, todos os valores deverão ser normalizados e as saídas também deverão ser codificadas, à medida que deixarem a rede.</span><span class="sxs-lookup"><span data-stu-id="a05a7-197">However, if multiple attributes are used for input and prediction, the model must create multiple networks; therefore, all values must be normalized, and the outputs too must be encoded as they exit the network.</span></span>  
  
 <span data-ttu-id="a05a7-198">A codificação de entradas se baseia em somar cada valor discreto nos casos de treinamento e multiplicar esse valor por seu peso.</span><span class="sxs-lookup"><span data-stu-id="a05a7-198">Encoding for inputs is based on summing each discrete value in the training cases, and multiplying that value by its weight.</span></span> <span data-ttu-id="a05a7-199">Esse processo é denominado *soma ponderada*, que é passada à função de ativação na camada oculta.</span><span class="sxs-lookup"><span data-stu-id="a05a7-199">This is called a *weighted sum*, which is passed to the activation function in the hidden layer.</span></span> <span data-ttu-id="a05a7-200">Uma pontuação z é usada para codificação, da seguinte forma:</span><span class="sxs-lookup"><span data-stu-id="a05a7-200">A z-score is used for encoding, as follows:</span></span>  
  
 <span data-ttu-id="a05a7-201">**Valores discretos**</span><span class="sxs-lookup"><span data-stu-id="a05a7-201">**Discrete values**</span></span>  
  
 <span data-ttu-id="a05a7-202">μ = p-a probabilidade anterior de um estado</span><span class="sxs-lookup"><span data-stu-id="a05a7-202">μ = p - the prior probability of a state</span></span>  
  
 <span data-ttu-id="a05a7-203">StdDev  = sqrt(p(1-p))</span><span class="sxs-lookup"><span data-stu-id="a05a7-203">StdDev  = sqrt(p(1-p))</span></span>  
  
 <span data-ttu-id="a05a7-204">**Valores contínuos**</span><span class="sxs-lookup"><span data-stu-id="a05a7-204">**Continuous values**</span></span>  
  
 <span data-ttu-id="a05a7-205">Valor presente = 1-μ/σ</span><span class="sxs-lookup"><span data-stu-id="a05a7-205">Value present= 1 - μ/σ</span></span>  
  
 <span data-ttu-id="a05a7-206">Nenhum valor existente =-μ/σ</span><span class="sxs-lookup"><span data-stu-id="a05a7-206">No existing value= -μ/σ</span></span>  
  
 <span data-ttu-id="a05a7-207">Após a codificação dos valores, as entradas passam pela soma ponderada, com as margens de rede como pesos.</span><span class="sxs-lookup"><span data-stu-id="a05a7-207">After the values have been encoded, the inputs go through weighted summing, with network edges as weights.</span></span>  
  
 <span data-ttu-id="a05a7-208">A codificação de saídas usa a função sigmoide que tem propriedades que a tornam muito útil para previsão.</span><span class="sxs-lookup"><span data-stu-id="a05a7-208">Encoding for outputs uses the sigmoid function, which has properties that make it very useful for prediction.</span></span> <span data-ttu-id="a05a7-209">Uma dessas propriedades é que, independentemente do modo como os valores originais são escalonados e independentemente se os valores são negativos ou positivos, a saída dessa função sempre é um valor entre 0 e 1, o que é adequado para estimar probabilidades.</span><span class="sxs-lookup"><span data-stu-id="a05a7-209">One such property is that, regardless of how the original values are scaled, and regardless of whether values are negative or positive, the output of this function is always a value between 0 and 1, which is suited for estimating probabilities.</span></span> <span data-ttu-id="a05a7-210">Outra propriedade útil é que a função sigmoide tem um efeito de atenuação, de modo que à medida que o valor se afasta do ponto de inflexão, a probabilidade de o valor avançar é de 0 ou 1, mas lentamente.</span><span class="sxs-lookup"><span data-stu-id="a05a7-210">Another useful property is that the sigmoid function has a smoothing effect, so that as values move farther away from point of inflection, the probability for the value moves towards 0 or 1, but slowly.</span></span>  
  
## <a name="customizing-the-neural-network-algorithm"></a><span data-ttu-id="a05a7-211">Personalizando o algoritmo Rede Neural</span><span class="sxs-lookup"><span data-stu-id="a05a7-211">Customizing the Neural Network Algorithm</span></span>  
 <span data-ttu-id="a05a7-212">O algoritmo Rede Neural da [!INCLUDE[msCoName](../../includes/msconame-md.md)] tem suporte a vários parâmetros que afetam o comportamento, o desempenho e a precisão do modelo de mineração resultante.</span><span class="sxs-lookup"><span data-stu-id="a05a7-212">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Neural Network algorithm supports several parameters that affect the behavior, performance, and accuracy of the resulting mining model.</span></span> <span data-ttu-id="a05a7-213">Também é possível modificar o modo como o modelo processa dados definindo sinalizadores de modelagem nas colunas ou definindo sinalizadores de distribuição para especificar o modo como os valores na coluna são manipulados.</span><span class="sxs-lookup"><span data-stu-id="a05a7-213">You can also modify the way that the model processes data by setting modeling flags on columns, or by setting distribution flags to specify how values within the column are handled.</span></span>  
  
### <a name="setting-algorithm-parameters"></a><span data-ttu-id="a05a7-214">Definindo parâmetros de algoritmo</span><span class="sxs-lookup"><span data-stu-id="a05a7-214">Setting Algorithm Parameters</span></span>  
 <span data-ttu-id="a05a7-215">A tabela a seguir descreve os parâmetros que podem ser usados com o algoritmo Rede Neural da Microsoft.</span><span class="sxs-lookup"><span data-stu-id="a05a7-215">The following table describes the parameters that can be used with the Microsoft Neural Network algorithm.</span></span>  
  
 <span data-ttu-id="a05a7-216">HIDDEN_NODE_RATIO</span><span class="sxs-lookup"><span data-stu-id="a05a7-216">HIDDEN_NODE_RATIO</span></span>  
 <span data-ttu-id="a05a7-217">Especifica a proporção dos neurônios ocultos com os neurônios de entrada e saída.</span><span class="sxs-lookup"><span data-stu-id="a05a7-217">Specifies the ratio of hidden neurons to input and output neurons.</span></span> <span data-ttu-id="a05a7-218">A fórmula a seguir determina o número inicial de neurônios na camada oculta:</span><span class="sxs-lookup"><span data-stu-id="a05a7-218">The following formula determines the initial number of neurons in the hidden layer:</span></span>  
  
 <span data-ttu-id="a05a7-219">HIDDEN_NODE_RATIO \* SQRT (Total de neurônios de entrada \* Total de neurônios de saída)</span><span class="sxs-lookup"><span data-stu-id="a05a7-219">HIDDEN_NODE_RATIO \* SQRT(Total input neurons \* Total output neurons)</span></span>  
  
 <span data-ttu-id="a05a7-220">O valor padrão é 4.0.</span><span class="sxs-lookup"><span data-stu-id="a05a7-220">The default value is 4.0.</span></span>  
  
 <span data-ttu-id="a05a7-221">HOLDOUT_PERCENTAGE</span><span class="sxs-lookup"><span data-stu-id="a05a7-221">HOLDOUT_PERCENTAGE</span></span>  
 <span data-ttu-id="a05a7-222">Especifica a porcentagem de casos nos dados de treinamento que são usados para calcular o erro de dados de controle e que é utilizada como parte do critério de interrupção durante o treinamento do modelo de mineração.</span><span class="sxs-lookup"><span data-stu-id="a05a7-222">Specifies the percentage of cases within the training data used to calculate the holdout error, which is used as part of the stopping criteria while training the mining model.</span></span>  
  
 <span data-ttu-id="a05a7-223">O valor padrão é 30.</span><span class="sxs-lookup"><span data-stu-id="a05a7-223">The default value is 30.</span></span>  
  
 <span data-ttu-id="a05a7-224">HOLDOUT_SEED</span><span class="sxs-lookup"><span data-stu-id="a05a7-224">HOLDOUT_SEED</span></span>  
 <span data-ttu-id="a05a7-225">Especifica um número que é usado para semear o gerador pseudoaleatório quando o algoritmo determinar os dados de controle aleatoriamente.</span><span class="sxs-lookup"><span data-stu-id="a05a7-225">Specifies a number that is used to seed the pseudo-random generator when the algorithm randomly determines the holdout data.</span></span> <span data-ttu-id="a05a7-226">Se esse parâmetro for definido como 0, o algoritmo gerará a semente com base no nome do modelo de mineração, para garantir que o conteúdo do modelo permaneça o mesmo durante um novo processamento.</span><span class="sxs-lookup"><span data-stu-id="a05a7-226">If this parameter is set to 0, the algorithm generates the seed based on the name of the mining model, to guarantee that the model content remains the same during reprocessing.</span></span>  
  
 <span data-ttu-id="a05a7-227">O valor padrão é 0.</span><span class="sxs-lookup"><span data-stu-id="a05a7-227">The default value is 0.</span></span>  
  
 <span data-ttu-id="a05a7-228">MAXIMUM_INPUT_ATTRIBUTES</span><span class="sxs-lookup"><span data-stu-id="a05a7-228">MAXIMUM_INPUT_ATTRIBUTES</span></span>  
 <span data-ttu-id="a05a7-229">Define o número máximo de atributos de entrada que podem ser fornecidos ao algoritmo antes que a seleção de recursos seja empregada.</span><span class="sxs-lookup"><span data-stu-id="a05a7-229">Determines the maximum number of input attributes that can be supplied to the algorithm before feature selection is employed.</span></span> <span data-ttu-id="a05a7-230">Definir esse valor como 0 desabilita a seleção do recurso para os atributos de entrada.</span><span class="sxs-lookup"><span data-stu-id="a05a7-230">Setting this value to 0 disables feature selection for input attributes.</span></span>  
  
 <span data-ttu-id="a05a7-231">O valor padrão é 255.</span><span class="sxs-lookup"><span data-stu-id="a05a7-231">The default value is 255.</span></span>  
  
 <span data-ttu-id="a05a7-232">MAXIMUM_OUTPUT_ATTRIBUTES</span><span class="sxs-lookup"><span data-stu-id="a05a7-232">MAXIMUM_OUTPUT_ATTRIBUTES</span></span>  
 <span data-ttu-id="a05a7-233">Define o número máximo de atributos de saída que podem ser fornecidos ao algoritmo antes que a seleção de recursos seja empregada.</span><span class="sxs-lookup"><span data-stu-id="a05a7-233">Determines the maximum number of output attributes that can be supplied to the algorithm before feature selection is employed.</span></span> <span data-ttu-id="a05a7-234">Definir esse valor como 0 desabilita a seleção do recurso para os atributos de saída.</span><span class="sxs-lookup"><span data-stu-id="a05a7-234">Setting this value to 0 disables feature selection for output attributes.</span></span>  
  
 <span data-ttu-id="a05a7-235">O valor padrão é 255.</span><span class="sxs-lookup"><span data-stu-id="a05a7-235">The default value is 255.</span></span>  
  
 <span data-ttu-id="a05a7-236">MAXIMUM_STATES</span><span class="sxs-lookup"><span data-stu-id="a05a7-236">MAXIMUM_STATES</span></span>  
 <span data-ttu-id="a05a7-237">Especifica o número máximo de estados discreto por atributo para os quais o algoritmo dá suporte.</span><span class="sxs-lookup"><span data-stu-id="a05a7-237">Specifies the maximum number of discrete states per attribute that is supported by the algorithm.</span></span> <span data-ttu-id="a05a7-238">Se o número de estados para um atributo específico for maior do que o número especificado para esse parâmetro, o algoritmo usará os estados mais populares do atributo e tratará os demais estados como ausentes.</span><span class="sxs-lookup"><span data-stu-id="a05a7-238">If the number of states for a specific attribute is greater than the number that is specified for this parameter, the algorithm uses the most popular states for that attribute and treats the remaining states as missing.</span></span>  
  
 <span data-ttu-id="a05a7-239">O valor padrão é 100.</span><span class="sxs-lookup"><span data-stu-id="a05a7-239">The default value is 100.</span></span>  
  
 <span data-ttu-id="a05a7-240">SAMPLE_SIZE</span><span class="sxs-lookup"><span data-stu-id="a05a7-240">SAMPLE_SIZE</span></span>  
 <span data-ttu-id="a05a7-241">Especifica o número de casos a ser usado para treinar o modelo.</span><span class="sxs-lookup"><span data-stu-id="a05a7-241">Specifies the number of cases to be used to train the model.</span></span> <span data-ttu-id="a05a7-242">O algoritmo usa esse número ou a porcentagem do total de casos não incluídos nos dados de validação conforme especificado pelo parâmetro HOLDOUT_PERCENTAGE, o que tiver menor valor.</span><span class="sxs-lookup"><span data-stu-id="a05a7-242">The algorithm uses either this number or the percentage of total of cases not included in the holdout data as specified by the HOLDOUT_PERCENTAGE parameter, whichever value is smaller.</span></span>  
  
 <span data-ttu-id="a05a7-243">Em outras palavras, se HOLDOUT_PERCENTAGE for definido como 30, o algoritmo usará o valor desse parâmetro ou um valor igual a 70 por cento do número total de casos, o que for menor.</span><span class="sxs-lookup"><span data-stu-id="a05a7-243">In other words, if HOLDOUT_PERCENTAGE is set to 30, the algorithm will use either the value of this parameter, or a value equal to 70 percent of the total number of cases, whichever is smaller.</span></span>  
  
 <span data-ttu-id="a05a7-244">O valor padrão é 10000.</span><span class="sxs-lookup"><span data-stu-id="a05a7-244">The default value is 10000.</span></span>  
  
### <a name="modeling-flags"></a><span data-ttu-id="a05a7-245">Sinalizadores de modelagem</span><span class="sxs-lookup"><span data-stu-id="a05a7-245">Modeling Flags</span></span>  
 <span data-ttu-id="a05a7-246">Os sinalizadores de modelagem a seguir têm suporte para uso com o algoritmo Rede Neural da [!INCLUDE[msCoName](../../includes/msconame-md.md)] .</span><span class="sxs-lookup"><span data-stu-id="a05a7-246">The following modeling flags are supported for use with the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Neural Network algorithm.</span></span>  
  
 <span data-ttu-id="a05a7-247">NOT NULL</span><span class="sxs-lookup"><span data-stu-id="a05a7-247">NOT NULL</span></span>  
 <span data-ttu-id="a05a7-248">Indica que a coluna não pode conter um nulo.</span><span class="sxs-lookup"><span data-stu-id="a05a7-248">Indicates that the column cannot contain a null.</span></span> <span data-ttu-id="a05a7-249">Um erro ocorrerá se o Analysis Services encontrar um valor nulo durante o treinamento do modelo.</span><span class="sxs-lookup"><span data-stu-id="a05a7-249">An error will result if Analysis Services encounters a null during model training.</span></span>  
  
 <span data-ttu-id="a05a7-250">Aplica-se às colunas de estrutura de mineração.</span><span class="sxs-lookup"><span data-stu-id="a05a7-250">Applies to mining structure columns.</span></span>  
  
 <span data-ttu-id="a05a7-251">MODEL_EXISTENCE_ONLY</span><span class="sxs-lookup"><span data-stu-id="a05a7-251">MODEL_EXISTENCE_ONLY</span></span>  
 <span data-ttu-id="a05a7-252">Indica que o modelo deve considerar apenas se um valor existe para o atributo ou se um valor está ausente.</span><span class="sxs-lookup"><span data-stu-id="a05a7-252">Indicates that the model should only consider whether a value exists for the attribute or if a value is missing.</span></span> <span data-ttu-id="a05a7-253">O valor exato não importa.</span><span class="sxs-lookup"><span data-stu-id="a05a7-253">The exact value does not matter.</span></span>  
  
 <span data-ttu-id="a05a7-254">Aplica-se às colunas de modelo de mineração.</span><span class="sxs-lookup"><span data-stu-id="a05a7-254">Applies to mining model columns.</span></span>  
  
### <a name="distribution-flags"></a><span data-ttu-id="a05a7-255">Sinalizadores de distribuição</span><span class="sxs-lookup"><span data-stu-id="a05a7-255">Distribution Flags</span></span>  
 <span data-ttu-id="a05a7-256">Os sinalizadores de distribuição a seguir têm suporte para uso com o algoritmo Rede Neural da [!INCLUDE[msCoName](../../includes/msconame-md.md)] .</span><span class="sxs-lookup"><span data-stu-id="a05a7-256">The following distribution flags are supported for use with the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Neural Network algorithm.</span></span> <span data-ttu-id="a05a7-257">Os sinalizadores são usados como dicas para o modelo apenas; se o algoritmo detectar uma distribuição diferente, ele usará a distribuição encontrada, não aquela fornecida na dica.</span><span class="sxs-lookup"><span data-stu-id="a05a7-257">The flags are used as hints to the model only; if the algorithm detects a different distribution it will use the found distribution, not the distribution provided in the hint.</span></span>  
  
 <span data-ttu-id="a05a7-258">Normal</span><span class="sxs-lookup"><span data-stu-id="a05a7-258">Normal</span></span>  
 <span data-ttu-id="a05a7-259">Indica que os valores dentro da coluna devem ser tratados como se representam a distribuição normal ou gaussiana.</span><span class="sxs-lookup"><span data-stu-id="a05a7-259">Indicates that values within the column should be treated as though they represent the normal, or Gaussian, distribution.</span></span>  
  
 <span data-ttu-id="a05a7-260">Uniforme</span><span class="sxs-lookup"><span data-stu-id="a05a7-260">Uniform</span></span>  
 <span data-ttu-id="a05a7-261">Indica que os valores dentro da coluna devem ser tratados como se fossem distribuídos uniformemente; ou seja, a probabilidade de qualquer valor é aproximadamente igual e é uma função do número total de valores.</span><span class="sxs-lookup"><span data-stu-id="a05a7-261">Indicates that values within the column should be treated as though they are distributed uniformly; that is, the probability of any value is roughly equal, and is a function of the total number of values.</span></span>  
  
 <span data-ttu-id="a05a7-262">Log Normal</span><span class="sxs-lookup"><span data-stu-id="a05a7-262">Log Normal</span></span>  
 <span data-ttu-id="a05a7-263">Indica que os valores na coluna devem ser tratados como se estivessem distribuídos de acordo com a curva *log normal* , o que significa que o logaritmo dos valores será distribuído normalmente.</span><span class="sxs-lookup"><span data-stu-id="a05a7-263">Indicates that values within the column should be treated as though distributed according to the *log normal* curve, which means that the logarithm of the values is distributed normally.</span></span>  
  
## <a name="requirements"></a><span data-ttu-id="a05a7-264">Requisitos</span><span class="sxs-lookup"><span data-stu-id="a05a7-264">Requirements</span></span>  
 <span data-ttu-id="a05a7-265">Um modelo de rede neural deve conter pelo menos uma coluna de entrada e uma coluna de saída.</span><span class="sxs-lookup"><span data-stu-id="a05a7-265">A neural network model must contain at least one input column and one output column.</span></span>  
  
### <a name="input-and-predictable-columns"></a><span data-ttu-id="a05a7-266">Colunas de entrada e colunas previsíveis</span><span class="sxs-lookup"><span data-stu-id="a05a7-266">Input and Predictable Columns</span></span>  
 <span data-ttu-id="a05a7-267">O algoritmo Rede Neural da [!INCLUDE[msCoName](../../includes/msconame-md.md)] dá suporte a colunas de entrada e colunas previsíveis específicas que são listadas na tabela a seguir.</span><span class="sxs-lookup"><span data-stu-id="a05a7-267">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Neural Network algorithm supports the specific input columns and predictable columns that are listed in the following table.</span></span>  
  
|<span data-ttu-id="a05a7-268">Column</span><span class="sxs-lookup"><span data-stu-id="a05a7-268">Column</span></span>|<span data-ttu-id="a05a7-269">Tipos de conteúdo</span><span class="sxs-lookup"><span data-stu-id="a05a7-269">Content types</span></span>|  
|------------|-------------------|  
|<span data-ttu-id="a05a7-270">Atributo de entrada</span><span class="sxs-lookup"><span data-stu-id="a05a7-270">Input attribute</span></span>|<span data-ttu-id="a05a7-271">Contínuo, cíclico, discreto, diferenciado, chave, tabela, e ordenado</span><span class="sxs-lookup"><span data-stu-id="a05a7-271">Continuous, Cyclical, Discrete, Discretized, Key, Table, and Ordered</span></span>|  
|<span data-ttu-id="a05a7-272">Atributo previsível</span><span class="sxs-lookup"><span data-stu-id="a05a7-272">Predictable attribute</span></span>|<span data-ttu-id="a05a7-273">Contínuo, cíclico, discreto, diferenciado, e ordenado</span><span class="sxs-lookup"><span data-stu-id="a05a7-273">Continuous, Cyclical, Discrete, Discretized, and Ordered</span></span>|  
  
> [!NOTE]  
>  <span data-ttu-id="a05a7-274">Os tipos de conteúdo Cíclico e Ordenado têm suporte, mas o algoritmo os trata como valores discretos e não executa processamento especial.</span><span class="sxs-lookup"><span data-stu-id="a05a7-274">Cyclical and Ordered content types are supported, but the algorithm treats them as discrete values and does not perform special processing.</span></span>  
  
## <a name="see-also"></a><span data-ttu-id="a05a7-275">Consulte Também</span><span class="sxs-lookup"><span data-stu-id="a05a7-275">See Also</span></span>  
 <span data-ttu-id="a05a7-276">[Algoritmo rede neural da Microsoft](microsoft-neural-network-algorithm.md) </span><span class="sxs-lookup"><span data-stu-id="a05a7-276">[Microsoft Neural Network Algorithm](microsoft-neural-network-algorithm.md) </span></span>  
 <span data-ttu-id="a05a7-277">[Conteúdo do modelo de mineração para modelos de rede neural &#40;Analysis Services&#41;de mineração de dados](mining-model-content-for-neural-network-models-analysis-services-data-mining.md) </span><span class="sxs-lookup"><span data-stu-id="a05a7-277">[Mining Model Content for Neural Network Models &#40;Analysis Services - Data Mining&#41;](mining-model-content-for-neural-network-models-analysis-services-data-mining.md) </span></span>  
 [<span data-ttu-id="a05a7-278">Neural Network Model Query Examples</span><span class="sxs-lookup"><span data-stu-id="a05a7-278">Neural Network Model Query Examples</span></span>](neural-network-model-query-examples.md)  
  
  
