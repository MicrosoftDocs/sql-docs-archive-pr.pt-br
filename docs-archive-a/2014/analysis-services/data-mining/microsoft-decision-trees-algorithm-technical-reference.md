---
title: Referência técnica do algoritmo árvores de decisão da Microsoft | Microsoft Docs
ms.custom: ''
ms.date: 06/13/2017
ms.prod: sql-server-2014
ms.reviewer: ''
ms.technology: analysis-services
ms.topic: conceptual
helpviewer_keywords:
- MAXIMUM_INPUT_ATTRIBUTES parameter
- SPLIT_METHOD parameter
- MINIMUM_SUPPORT parameter
- MAXIMUM_OUTPUT_ATTRIBUTES parameter
- FORCED_REGRESSOR parameter
- decision tree algorithms [Analysis Services]
- decision trees [Analysis Services]
- COMPLEXITY_PENALTY parameter
- SCORE_METHOD parameter
ms.assetid: 1e9f7969-0aa6-465a-b3ea-57b8d1c7a1fd
author: minewiskan
ms.author: owend
ms.openlocfilehash: 0cd0cd3100d0ed1213183815ae41f17cee3baa68
ms.sourcegitcommit: ad4d92dce894592a259721a1571b1d8736abacdb
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 08/04/2020
ms.locfileid: "87575447"
---
# <a name="microsoft-decision-trees-algorithm-technical-reference"></a><span data-ttu-id="19e44-102">Referência técnica do algoritmo Árvores de Decisão da Microsoft</span><span class="sxs-lookup"><span data-stu-id="19e44-102">Microsoft Decision Trees Algorithm Technical Reference</span></span>
  <span data-ttu-id="19e44-103">O algoritmo Árvores de Decisão da [!INCLUDE[msCoName](../../includes/msconame-md.md)] é um híbrido que incorpora métodos diferentes para a criação de uma árvore e dá suporte a várias tarefas analíticas, incluindo regressão, classificação e associação.</span><span class="sxs-lookup"><span data-stu-id="19e44-103">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm is a hybrid algorithm that incorporates different methods for creating a tree, and supports multiple analytic tasks, including regression, classification, and association.</span></span> <span data-ttu-id="19e44-104">O algoritmo Árvores de Decisão da Microsoft é dá suporte à modelagem de atributos discretos e contínuos.</span><span class="sxs-lookup"><span data-stu-id="19e44-104">The Microsoft Decision Trees algorithm supports modeling of both discrete and continuous attributes.</span></span>  
  
 <span data-ttu-id="19e44-105">Este tópico explica a implementação do algoritmo, descreve como personalizar o comportamento do algoritmo para tarefas diferentes e fornece links para informações adicionais sobre como consultar modelos de árvore de decisão.</span><span class="sxs-lookup"><span data-stu-id="19e44-105">This topic explains the implementation of the algorithm, describes how to customize the behavior of the algorithm for different tasks, and provides links to additional information about querying decision tree models.</span></span>  
  
## <a name="implementation-of-the-decision-trees-algorithm"></a><span data-ttu-id="19e44-106">Implementação do algoritmo Árvores de Decisão</span><span class="sxs-lookup"><span data-stu-id="19e44-106">Implementation of the Decision Trees Algorithm</span></span>  
 <span data-ttu-id="19e44-107">O algoritmo Árvores de Decisão da Microsoft aplica a abordagem Bayesiana para aprender os modelos de interação causal obtendo distribuições posteriores aproximadas dos modelos.</span><span class="sxs-lookup"><span data-stu-id="19e44-107">The Microsoft Decision Trees algorithm applies the Bayesian approach to learning causal interaction models by obtaining approximate posterior distributions for the models.</span></span> <span data-ttu-id="19e44-108">Para obter uma explicação detalhada dessa abordagem, consulte o documento no site do Microsoft Research, por [Estrutura e aprendizado de parâmetro](https://go.microsoft.com/fwlink/?LinkId=237640&clcid=0x409).</span><span class="sxs-lookup"><span data-stu-id="19e44-108">For a detailed explanation of this approach, see the paper on the Microsoft Research site, by [Structure and Parameter Learning](https://go.microsoft.com/fwlink/?LinkId=237640&clcid=0x409).</span></span>  
  
 <span data-ttu-id="19e44-109">A metodologia para avaliar o valor das informações *a priori* necessárias para o aprendizado se baseia na suposição da *equivalência de probabilidade*.</span><span class="sxs-lookup"><span data-stu-id="19e44-109">The methodology for assessing the information value of the *priors* needed for learning is based on the assumption of *likelihood equivalence*.</span></span> <span data-ttu-id="19e44-110">Essa pressuposição afirma que os dados não devem ajudar a discriminar estruturas de rede que de outra forma representam as mesmas asserções de independência condicional.</span><span class="sxs-lookup"><span data-stu-id="19e44-110">This assumption says that data should not help to discriminate network structures that otherwise represent the same assertions of conditional independence.</span></span> <span data-ttu-id="19e44-111">Pressupõe-se que cada caso tenha uma única rede Bayesiana a priori e uma única medida de confiança para essa rede.</span><span class="sxs-lookup"><span data-stu-id="19e44-111">Each case is assumed to have a single Bayesian prior network and a single measure of confidence for that network.</span></span>  
  
 <span data-ttu-id="19e44-112">Com o uso dessas redes a priori, o algoritmo calcula as *probabilidades posteriores* relativas das estruturas de rede, de acordo com os dados de treinamento atuais, e identifica as estruturas de rede que têm as probabilidades posteriores mais altas.</span><span class="sxs-lookup"><span data-stu-id="19e44-112">Using these prior networks, the algorithm then computes the relative *posterior probabilities* of network structures given the current training data, and identifies the network structures that have the highest posterior probabilities.</span></span>  
  
 <span data-ttu-id="19e44-113">O algoritmo Árvores de Decisão da Microsoft usa métodos diferentes para calcular a melhor árvore.</span><span class="sxs-lookup"><span data-stu-id="19e44-113">The Microsoft Decision Trees algorithm uses different methods to compute the best tree.</span></span> <span data-ttu-id="19e44-114">O método usado depende da tarefa que pode ser regressão linear, classificação ou análise de associação.</span><span class="sxs-lookup"><span data-stu-id="19e44-114">The method used depends on the task, which can be linear regression, classification, or association analysis.</span></span> <span data-ttu-id="19e44-115">Um único modelo pode conter várias árvores para atributos previsíveis diferentes.</span><span class="sxs-lookup"><span data-stu-id="19e44-115">A single model can contain multiple trees for different predictable attributes.</span></span> <span data-ttu-id="19e44-116">Além disso, cada árvore pode conter várias ramificações, de acordo com a quantidade de atributos e valores nos dados.</span><span class="sxs-lookup"><span data-stu-id="19e44-116">Moreover, each tree can contain multiple branches, depending on how many attributes and values there are in the data.</span></span> <span data-ttu-id="19e44-117">A forma e a intensidade da árvore criada em um determinado modelo dependem do método de pontuação e de outros parâmetros utilizados.</span><span class="sxs-lookup"><span data-stu-id="19e44-117">The shape and depth of the tree built in a particular model depends on the scoring method and other parameters that were used.</span></span> <span data-ttu-id="19e44-118">Alterações aos parâmetros também podem afetar o local em que os nós são divididos.</span><span class="sxs-lookup"><span data-stu-id="19e44-118">Changes in the parameters can also affect where the nodes split.</span></span>  
  
### <a name="building-the-tree"></a><span data-ttu-id="19e44-119">Criando a árvore</span><span class="sxs-lookup"><span data-stu-id="19e44-119">Building the Tree</span></span>  
 <span data-ttu-id="19e44-120">Quando o algoritmo Árvores de Decisão da Microsoft cria o conjunto de valores de entrada possíveis, ele executa *feature selection* para identificar os atributos e os valores que fornecem a maioria das informações e remove da consideração os valores que são muito raros.</span><span class="sxs-lookup"><span data-stu-id="19e44-120">When the Microsoft Decision Trees algorithm creates the set of possible input values, it performs *feature selection* to identify the attributes and values that provide the most information, and removes from consideration the values that are very rare.</span></span> <span data-ttu-id="19e44-121">O algoritmo também agrupa valores em *compartimentos*, para criar agrupamentos de valores que podem ser processados como uma unidade para otimizar o desempenho.</span><span class="sxs-lookup"><span data-stu-id="19e44-121">The algorithm also groups values into *bins*, to create groupings of values that can be processed as a unit to optimize performance.</span></span>  
  
 <span data-ttu-id="19e44-122">Uma árvore é criada com a determinação das correlações entre uma entrada e o resultado pretendido.</span><span class="sxs-lookup"><span data-stu-id="19e44-122">A tree is built by determining the correlations between an input and the targeted outcome.</span></span> <span data-ttu-id="19e44-123">Depois que todos os atributos tiverem sido correlacionados, o algoritmo identificará o único atributo que separa mais claramente os resultados.</span><span class="sxs-lookup"><span data-stu-id="19e44-123">After all the attributes have been correlated, the algorithm identifies the single attribute that most cleanly separates the outcomes.</span></span> <span data-ttu-id="19e44-124">Este ponto da melhor separação é medido com o uso de uma equação que calcula o ganho de informações.</span><span class="sxs-lookup"><span data-stu-id="19e44-124">This point of the best separation is measured by using an equation that calculates information gain.</span></span> <span data-ttu-id="19e44-125">o atributo com a melhor pontuação de ganho de informações é usado para dividir os casos em subconjuntos, que são analisados recursivamente pelo mesmo processo, até que não seja mais possível dividir a árvore.</span><span class="sxs-lookup"><span data-stu-id="19e44-125">The attribute that has the best score for information gain is used to divide the cases into subsets, which are then recursively analyzed by the same process, until the tree cannot be split any more.</span></span>  
  
 <span data-ttu-id="19e44-126">A equação exata usada para avaliar o ganho de informações depende dos parâmetros definidos quando você criou o algoritmo, do tipo de dados da coluna previsível e do tipo de dados da entrada.</span><span class="sxs-lookup"><span data-stu-id="19e44-126">The exact equation used to evaluate information gain depends on the parameters set when you created the algorithm, the data type of the predictable column, and the data type of the input.</span></span>  
  
### <a name="discrete-and-continuous-inputs"></a><span data-ttu-id="19e44-127">Entradas discretas e contínuas</span><span class="sxs-lookup"><span data-stu-id="19e44-127">Discrete and Continuous Inputs</span></span>  
 <span data-ttu-id="19e44-128">Quando o atributo previsível é discreto e as entradas previsíveis também, contar os resultados por entrada é uma questão de criar uma matriz e gerar pontuações para cada célula na matriz.</span><span class="sxs-lookup"><span data-stu-id="19e44-128">When the predictable attribute is discrete and the inputs are discrete, counting the outcomes per input is a matter of creating a matrix and generating scores for each cell in the matrix.</span></span>  
  
 <span data-ttu-id="19e44-129">No entanto, quando o atributo previsível é discreto e as entradas são contínuas, a entrada das colunas contínuas é discreta automaticamente.</span><span class="sxs-lookup"><span data-stu-id="19e44-129">However, when the predictable attribute is discrete and the inputs are continuous, the input of the continuous columns are automatically discretized.</span></span> <span data-ttu-id="19e44-130">Você pode aceitar o padrão e fazer com que o [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] encontre o número ideal de compartimentos ou pode controlar a maneira pela qual as entradas contínuas são discretizadas definindo as propriedades <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationMethod%2A> e <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationBucketCount%2A> .</span><span class="sxs-lookup"><span data-stu-id="19e44-130">You can accept the default and have [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] find the optimum number of bins, or you can control the manner in which continuous inputs are discretized by setting the <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationMethod%2A> and <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationBucketCount%2A> properties.</span></span> <span data-ttu-id="19e44-131">Para obter mais informações, consulte [Alterar a discretização de uma coluna em um modelo de mineração](change-the-discretization-of-a-column-in-a-mining-model.md).</span><span class="sxs-lookup"><span data-stu-id="19e44-131">For more information, see [Change the Discretization of a Column in a Mining Model](change-the-discretization-of-a-column-in-a-mining-model.md).</span></span>  
  
 <span data-ttu-id="19e44-132">No caso de atributos contínuos, o algoritmo usa a regressão linear para determinar onde uma árvore de decisão se divide.</span><span class="sxs-lookup"><span data-stu-id="19e44-132">For continuous attributes, the algorithm uses linear regression to determine where a decision tree splits.</span></span>  
  
 <span data-ttu-id="19e44-133">Quando o atributo previsível é um tipo de dados numérico contínuo, a seleção de recursos é aplicada às saídas também, para reduzir o número possível de resultados e criar o modelo mais rapidamente.</span><span class="sxs-lookup"><span data-stu-id="19e44-133">When the predictable attribute is a continuous numeric data type, feature selection is applied to the outputs as well, to reduce the possible number of outcomes and build the model faster.</span></span> <span data-ttu-id="19e44-134">Você pode alterar o limite de seleção de recursos e, portanto, aumentar ou diminuir o número de valores possíveis configurando o parâmetro MAXIMUM_OUTPUT_ATTRIBUTES.</span><span class="sxs-lookup"><span data-stu-id="19e44-134">You can change the threshold for feature selection and thereby increase or decrease the number of possible values by setting the MAXIMUM_OUTPUT_ATTRIBUTES parameter.</span></span>  
  
 <span data-ttu-id="19e44-135">Para obter uma explicação mais detalhada sobre como o algoritmo Árvores de Decisão da [!INCLUDE[msCoName](../../includes/msconame-md.md)] funciona com colunas previsíveis distintas, consulte [Aprendendo sobre redes Bayesianas: A combinação de dados de conhecimento e estatísticos](https://go.microsoft.com/fwlink/?LinkId=45963).</span><span class="sxs-lookup"><span data-stu-id="19e44-135">For a more detained explanation about how the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm works with discrete predictable columns, see [Learning Bayesian Networks: The Combination of Knowledge and Statistical Data](https://go.microsoft.com/fwlink/?LinkId=45963).</span></span> <span data-ttu-id="19e44-136">Para obter mais informações sobre como o algoritmo Árvores de Decisão da [!INCLUDE[msCoName](../../includes/msconame-md.md)] funciona com uma coluna previsível contínua, consulte o apêndice de [Modelos de árvore de regressão automática para análise de série temporal](https://go.microsoft.com/fwlink/?LinkId=45966).</span><span class="sxs-lookup"><span data-stu-id="19e44-136">For more information about how the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm works with a continuous predictable column, see the appendix of [Autoregressive Tree Models for Time-Series Analysis](https://go.microsoft.com/fwlink/?LinkId=45966).</span></span>  
  
### <a name="scoring-methods-and-feature-selection"></a><span data-ttu-id="19e44-137">Métodos de pontuação e seleção de recursos</span><span class="sxs-lookup"><span data-stu-id="19e44-137">Scoring Methods and Feature Selection</span></span>  
 <span data-ttu-id="19e44-138">O algoritmo Árvores de Decisão da Microsoft oferece três fórmulas para ganho de informações de pontuação: entropia de Shannon, rede Bayesiana com K2 a priori e rede Bayesiana com uma distribuição Dirichlet uniforme a priori.</span><span class="sxs-lookup"><span data-stu-id="19e44-138">The Microsoft Decision Trees algorithm offers three formulas for scoring information gain: Shannon's entropy, Bayesian network with K2 prior, and Bayesian network with a uniform Dirichlet distribution of priors.</span></span> <span data-ttu-id="19e44-139">Todos os três métodos são bem-estabelecidos no campo de mineração de dados.</span><span class="sxs-lookup"><span data-stu-id="19e44-139">All three methods are well established in the data mining field.</span></span> <span data-ttu-id="19e44-140">É recomendável fazer experiências com parâmetros e métodos de pontuação diferentes para determinar aqueles que fornecem os melhores resultados.</span><span class="sxs-lookup"><span data-stu-id="19e44-140">We recommend that you experiment with different parameters and scoring methods to determine which provides the best results.</span></span> <span data-ttu-id="19e44-141">Para obter mais informações sobre esses métodos de pontuação, consulte [Feature Selection](../../sql-server/install/feature-selection.md).</span><span class="sxs-lookup"><span data-stu-id="19e44-141">For more information about these scoring methods, see [Feature Selection](../../sql-server/install/feature-selection.md).</span></span>  
  
 <span data-ttu-id="19e44-142">Todos os algoritmos de mineração de dados [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] usam seleção de recursos automaticamente para melhorar a análise e reduzir a carga de processamento.</span><span class="sxs-lookup"><span data-stu-id="19e44-142">All [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] data mining algorithms automatically use feature selection to improve analysis and reduce processing load.</span></span> <span data-ttu-id="19e44-143">O método usado para seleção de recursos depende do algoritmo utilizado para criar o modelo.</span><span class="sxs-lookup"><span data-stu-id="19e44-143">The method used for feature selection depends on the algorithm that is used to build the model.</span></span> <span data-ttu-id="19e44-144">Os parâmetros de algoritmo que controlam seleção de recursos para um modelo de árvores de decisão são MAXIMUM_INPUT_ATTRIBUTES e MAXIMUM_OUTPUT.</span><span class="sxs-lookup"><span data-stu-id="19e44-144">The algorithm parameters that control feature selection for a decision trees model are MAXIMUM_INPUT_ATTRIBUTES and MAXIMUM_OUTPUT.</span></span>  
  
|<span data-ttu-id="19e44-145">Algoritmo</span><span class="sxs-lookup"><span data-stu-id="19e44-145">Algorithm</span></span>|<span data-ttu-id="19e44-146">Método de análise</span><span class="sxs-lookup"><span data-stu-id="19e44-146">Method of analysis</span></span>|<span data-ttu-id="19e44-147">Comentários</span><span class="sxs-lookup"><span data-stu-id="19e44-147">Comments</span></span>|  
|---------------|------------------------|--------------|  
|<span data-ttu-id="19e44-148">Árvores de decisão</span><span class="sxs-lookup"><span data-stu-id="19e44-148">Decision Trees</span></span>|<span data-ttu-id="19e44-149">Pontuação de interesse</span><span class="sxs-lookup"><span data-stu-id="19e44-149">Interestingness score</span></span><br /><br /> <span data-ttu-id="19e44-150">Entropia de Shannon</span><span class="sxs-lookup"><span data-stu-id="19e44-150">Shannon's Entropy</span></span><br /><br /> <span data-ttu-id="19e44-151">Bayesian com K2 a priori</span><span class="sxs-lookup"><span data-stu-id="19e44-151">Bayesian with K2 Prior</span></span><br /><br /> <span data-ttu-id="19e44-152">Bayesian Dirichlet com uniforme a priori (padrão)</span><span class="sxs-lookup"><span data-stu-id="19e44-152">Bayesian Dirichlet with uniform prior (default)</span></span>|<span data-ttu-id="19e44-153">Se qualquer coluna contiver valores contínuos não binários, a pontuação de interesse será usada em todas as colunas para garantir a consistência.</span><span class="sxs-lookup"><span data-stu-id="19e44-153">If any columns contain non-binary continuous values, the interestingness score is used for all columns, to ensure consistency.</span></span> <span data-ttu-id="19e44-154">Caso contrário, será usado o método padrão ou o especificado.</span><span class="sxs-lookup"><span data-stu-id="19e44-154">Otherwise, the default or specified method is used.</span></span>|  
|<span data-ttu-id="19e44-155">Regressão Linear</span><span class="sxs-lookup"><span data-stu-id="19e44-155">Linear Regression</span></span>|<span data-ttu-id="19e44-156">Pontuação de interesse</span><span class="sxs-lookup"><span data-stu-id="19e44-156">Interestingness score</span></span>|<span data-ttu-id="19e44-157">A Regressão Linear usa apenas o interesse, pois suporta apenas colunas contínuas.</span><span class="sxs-lookup"><span data-stu-id="19e44-157">Linear Regression only uses interestingness, because it only supports continuous columns.</span></span>|  
  
### <a name="scalability-and-performance"></a><span data-ttu-id="19e44-158">Desempenho e escalabilidade</span><span class="sxs-lookup"><span data-stu-id="19e44-158">Scalability and Performance</span></span>  
 <span data-ttu-id="19e44-159">A classificação é uma estratégia de mineração de dados importante.</span><span class="sxs-lookup"><span data-stu-id="19e44-159">Classification is an important data mining strategy.</span></span> <span data-ttu-id="19e44-160">Em geral, a quantidade de informações necessária para classificar os casos aumenta em proporção direta ao número de registros de entrada.</span><span class="sxs-lookup"><span data-stu-id="19e44-160">Generally, the amount of information that is needed to classify the cases grows in direct proportion to the number of input records.</span></span> <span data-ttu-id="19e44-161">Isso limita o tamanho dos dados que podem ser classificados.</span><span class="sxs-lookup"><span data-stu-id="19e44-161">This limits the size of the data that can be classified.</span></span> <span data-ttu-id="19e44-162">O algoritmo Árvores de Decisão da Microsoft usa os seguintes métodos para resolver esses problemas, melhorar o desempenho e eliminar as restrições de memória:</span><span class="sxs-lookup"><span data-stu-id="19e44-162">The Microsoft Decision Trees algorithm using uses the following methods to resolve these problems, improve performance, and eliminate memory restrictions:</span></span>  
  
-   <span data-ttu-id="19e44-163">Seleção de recursos para otimizar a seleção dos atributos.</span><span class="sxs-lookup"><span data-stu-id="19e44-163">Feature selection to optimize the selection of attributes.</span></span>  
  
-   <span data-ttu-id="19e44-164">Pontuação Bayesiana para controlar o crescimento da árvore.</span><span class="sxs-lookup"><span data-stu-id="19e44-164">Bayesian scoring to control tree growth.</span></span>  
  
-   <span data-ttu-id="19e44-165">Otimização de compartimentos para atributos contínuos.</span><span class="sxs-lookup"><span data-stu-id="19e44-165">Optimization of binning for continuous attributes.</span></span>  
  
-   <span data-ttu-id="19e44-166">Agrupamento dinâmico de valores de entrada para determinar os valores mais importantes.</span><span class="sxs-lookup"><span data-stu-id="19e44-166">Dynamic grouping of input values to determine the most important values.</span></span>  
  
 <span data-ttu-id="19e44-167">O algoritmo Árvores de Decisão da Microsoft é rápido e escalonável, e foi projetado para paralelização fácil, o que significa que todos os processadores funcionam em conjunto para criar um único modelo consistente.</span><span class="sxs-lookup"><span data-stu-id="19e44-167">The Microsoft Decision Trees algorithm is fast and scalable, and has been designed to be easily parallelized, meaning that all processors work together to build a single, consistent model.</span></span> <span data-ttu-id="19e44-168">A combinação dessas características torna o classificador de árvore de decisão uma ferramenta ideal para mineração de dados.</span><span class="sxs-lookup"><span data-stu-id="19e44-168">The combination of these characteristics makes the decision-tree classifier an ideal tool for data mining.</span></span>  
  
 <span data-ttu-id="19e44-169">Se as restrições de desempenho forem graves, talvez você possa melhorar o tempo de processamento durante o treinamento de um modelo de árvore de decisão usando os métodos a seguir.</span><span class="sxs-lookup"><span data-stu-id="19e44-169">If performance constraints are severe, you might be able to improve processing time during the training of a decision tree model by using the following methods.</span></span> <span data-ttu-id="19e44-170">No entanto, se você fizer isso, saiba que eliminar atributos para melhorar o desempenho de processamento alterará os resultados do modelo e possivelmente o tornará menos representativo da população total.</span><span class="sxs-lookup"><span data-stu-id="19e44-170">However, if you do so, be aware that eliminating attributes to improve processing performance will change the results of the model, and possibly make it less representative of the total population.</span></span>  
  
-   <span data-ttu-id="19e44-171">Aumente o valor do parâmetro COMPLEXITY_PENALTY para limitar o crescimento de árvore.</span><span class="sxs-lookup"><span data-stu-id="19e44-171">Increase the value of the COMPLEXITY_PENALTY parameter to limit tree growth.</span></span>  
  
-   <span data-ttu-id="19e44-172">Limite o número de itens em modelos de associação para limitar o número de árvores criadas.</span><span class="sxs-lookup"><span data-stu-id="19e44-172">Limit the number of items in association models to limit the number of trees that are built.</span></span>  
  
-   <span data-ttu-id="19e44-173">Aumente o valor do parâmetro MINIMUM_SUPPORT para evitar sobreajuste.</span><span class="sxs-lookup"><span data-stu-id="19e44-173">Increase the value of the MINIMUM_SUPPORT parameter to avoid overfitting.</span></span>  
  
-   <span data-ttu-id="19e44-174">Restrinja o número de valores discretos de qualquer atributo para 10 ou menos.</span><span class="sxs-lookup"><span data-stu-id="19e44-174">Restrict the number of discrete values for any attribute to 10 or less.</span></span> <span data-ttu-id="19e44-175">Você pode tentar agrupar valores de modos diferentes em modelos diferentes.</span><span class="sxs-lookup"><span data-stu-id="19e44-175">You might try grouping values in different ways in different models.</span></span>  
  
    > [!NOTE]  
    >  <span data-ttu-id="19e44-176">É possível usar as ferramentas de exploração de dados disponíveis no  [!INCLUDE[ssISCurrent](../../includes/ssiscurrent-md.md)] para visualizar a distribuição de valores nos dados e agrupar os valores apropriadamente antes de iniciar a mineração de dados.</span><span class="sxs-lookup"><span data-stu-id="19e44-176">You can use the data exploration tools available in  [!INCLUDE[ssISCurrent](../../includes/ssiscurrent-md.md)] to visualize the distribution of values in your data and group your values appropriately before beginning data mining.</span></span> <span data-ttu-id="19e44-177">Para obter mais informações, consulte [Tarefa e Visualizador de Criação de Perfil de Dados](../../integration-services/control-flow/data-profiling-task-and-viewer.md).</span><span class="sxs-lookup"><span data-stu-id="19e44-177">For more information, see [Data Profiling Task and Viewer](../../integration-services/control-flow/data-profiling-task-and-viewer.md).</span></span> <span data-ttu-id="19e44-178">Também é possível usar os [Suplementos de Mineração de Dados para Excel 2007](https://www.microsoft.com/download/details.aspx?id=8569)para explorar, agrupar e rotular novamente os dados no Microsoft Excel.</span><span class="sxs-lookup"><span data-stu-id="19e44-178">You can also use the [Data Mining Add-ins for Excel 2007](https://www.microsoft.com/download/details.aspx?id=8569), to explore, group and relabel data in Microsoft Excel.</span></span>  
  
## <a name="customizing-the-decision-trees-algorithm"></a><span data-ttu-id="19e44-179">Personalizando o algoritmo Árvores de Decisão</span><span class="sxs-lookup"><span data-stu-id="19e44-179">Customizing the Decision Trees Algorithm</span></span>  
 <span data-ttu-id="19e44-180">O algoritmo Árvores de Decisão da [!INCLUDE[msCoName](../../includes/msconame-md.md)] tem suporte para parâmetros que afetam o desempenho e a precisão do modelo de mineração resultante.</span><span class="sxs-lookup"><span data-stu-id="19e44-180">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm supports parameters that affect the performance and accuracy of the resulting mining model.</span></span> <span data-ttu-id="19e44-181">Também é possível definir sinalizadores de modelagem nas colunas do modelo de mineração ou da estrutura de mineração para controlar a maneira como os dados são processados.</span><span class="sxs-lookup"><span data-stu-id="19e44-181">You can also set modeling flags on the mining model columns or mining structure columns to control the way that data is processed.</span></span>  
  
> [!NOTE]  
>  <span data-ttu-id="19e44-182">O algoritmo Árvores de Decisão da Microsoft está disponível em todas as edições do [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]; no entanto, alguns parâmetros avançados para personalizar o comportamento do algoritmo Árvores de Decisão da Microsoft estão disponíveis para uso apenas em edições específicas do [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)].</span><span class="sxs-lookup"><span data-stu-id="19e44-182">The Microsoft Decision Trees algorithm is available in all editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]; however, some advanced parameters for customizing the behavior of the Microsoft Decision Trees algorithm are available for use only in specific editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)].</span></span> <span data-ttu-id="19e44-183">Para obter uma lista de recursos com suporte nas edições do [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)] , consulte [recursos com suporte nas edições do SQL Server 2012](https://go.microsoft.com/fwlink/?linkid=232473) ( https://go.microsoft.com/fwlink/?linkid=232473) .</span><span class="sxs-lookup"><span data-stu-id="19e44-183">For a list of features that are supported by the editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)], see [Features Supported by the Editions of SQL Server 2012](https://go.microsoft.com/fwlink/?linkid=232473) (https://go.microsoft.com/fwlink/?linkid=232473).</span></span>  
  
### <a name="setting-algorithm-parameters"></a><span data-ttu-id="19e44-184">Definindo parâmetros de algoritmo</span><span class="sxs-lookup"><span data-stu-id="19e44-184">Setting Algorithm Parameters</span></span>  
 <span data-ttu-id="19e44-185">A tabela a seguir descreve os parâmetros que você pode usar com o algoritmo Árvores de Decisão da [!INCLUDE[msCoName](../../includes/msconame-md.md)] .</span><span class="sxs-lookup"><span data-stu-id="19e44-185">The following table describes the parameters that you can use with the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm.</span></span>  
  
 <span data-ttu-id="19e44-186">*COMPLEXITY_PENALTY*</span><span class="sxs-lookup"><span data-stu-id="19e44-186">*COMPLEXITY_PENALTY*</span></span>  
 <span data-ttu-id="19e44-187">Controla o crescimento da árvore de decisão.</span><span class="sxs-lookup"><span data-stu-id="19e44-187">Controls the growth of the decision tree.</span></span> <span data-ttu-id="19e44-188">Um valor baixo aumenta o número de divisões e um valor alto diminui o número de divisões.</span><span class="sxs-lookup"><span data-stu-id="19e44-188">A low value increases the number of splits, and a high value decreases the number of splits.</span></span> <span data-ttu-id="19e44-189">O valor padrão se baseia no número de atributos de um determinado modelo, conforme descrito na lista a seguir:</span><span class="sxs-lookup"><span data-stu-id="19e44-189">The default value is based on the number of attributes for a particular model, as described in the following list:</span></span>  
  
-   <span data-ttu-id="19e44-190">Para os atributos 1 a 9, o padrão é 0,5.</span><span class="sxs-lookup"><span data-stu-id="19e44-190">For 1 through 9 attributes, the default is 0.5.</span></span>  
  
-   <span data-ttu-id="19e44-191">Para 10 a 99 atributos, o padrão é 0,9.</span><span class="sxs-lookup"><span data-stu-id="19e44-191">For 10 through 99 attributes, the default is 0.9.</span></span>  
  
-   <span data-ttu-id="19e44-192">Para 100 ou mais atributos, o padrão é 0,99.</span><span class="sxs-lookup"><span data-stu-id="19e44-192">For 100 or more attributes, the default is 0.99.</span></span>  
  
 <span data-ttu-id="19e44-193">*FORCE_REGRESSOR*</span><span class="sxs-lookup"><span data-stu-id="19e44-193">*FORCE_REGRESSOR*</span></span>  
 <span data-ttu-id="19e44-194">Força o algoritmo a usar as colunas especificadas como regressores, independentemente da sua importância quando calculadas pelo algoritmo.</span><span class="sxs-lookup"><span data-stu-id="19e44-194">Forces the algorithm to use the specified columns as regressors, regardless of the importance of the columns as calculated by the algorithm.</span></span> <span data-ttu-id="19e44-195">Esse parâmetro é usado apenas para árvores de decisão que preveem um atributo contínuo.</span><span class="sxs-lookup"><span data-stu-id="19e44-195">This parameter is only used for decision trees that are predicting a continuous attribute.</span></span>  
  
> [!NOTE]  
>  <span data-ttu-id="19e44-196">Ao definir esse parâmetro, você força o algoritmo a tentar usar o atributo como um regressor.</span><span class="sxs-lookup"><span data-stu-id="19e44-196">By setting this parameter, you force the algorithm to try to use the attribute as a regressor.</span></span> <span data-ttu-id="19e44-197">No entanto, se o atributo será realmente usado como um regressor no modelo final dependerá dos resultados da análise.</span><span class="sxs-lookup"><span data-stu-id="19e44-197">However, whether the attribute is actually used as a regressor in the final model depends on the results of analysis.</span></span> <span data-ttu-id="19e44-198">Você pode descobrir quais colunas foram usadas como regressores consultando o conteúdo do modelo.</span><span class="sxs-lookup"><span data-stu-id="19e44-198">You can find out which columns were used as regressors by querying the model content.</span></span>  
  
 <span data-ttu-id="19e44-199">[Disponível somente em algumas edições do [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)] ]</span><span class="sxs-lookup"><span data-stu-id="19e44-199">[Available only in some editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)] ]</span></span>  
  
 <span data-ttu-id="19e44-200">*MAXIMUM_INPUT_ATTRIBUTES*</span><span class="sxs-lookup"><span data-stu-id="19e44-200">*MAXIMUM_INPUT_ATTRIBUTES*</span></span>  
 <span data-ttu-id="19e44-201">Define o número de atributos de entrada que o algoritmo pode manipular antes de invocar a seleção de recurso.</span><span class="sxs-lookup"><span data-stu-id="19e44-201">Defines the number of input attributes that the algorithm can handle before it invokes feature selection.</span></span>  
  
 <span data-ttu-id="19e44-202">O padrão é 255.</span><span class="sxs-lookup"><span data-stu-id="19e44-202">The default is 255.</span></span>  
  
 <span data-ttu-id="19e44-203">Defina este valor como 0 para desativar a seleção de recursos.</span><span class="sxs-lookup"><span data-stu-id="19e44-203">Set this value to 0 to turn off feature selection.</span></span>  
  
 <span data-ttu-id="19e44-204">[Disponível somente em algumas edições do [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]]</span><span class="sxs-lookup"><span data-stu-id="19e44-204">[Available only in some editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]]</span></span>  
  
 <span data-ttu-id="19e44-205">*MAXIMUM_OUTPUT_ATTRIBUTES*</span><span class="sxs-lookup"><span data-stu-id="19e44-205">*MAXIMUM_OUTPUT_ATTRIBUTES*</span></span>  
 <span data-ttu-id="19e44-206">Define o número de atributos de saída que o algoritmo pode manipular antes de invocar a seleção de recurso.</span><span class="sxs-lookup"><span data-stu-id="19e44-206">Defines the number of output attributes that the algorithm can handle before it invokes feature selection.</span></span>  
  
 <span data-ttu-id="19e44-207">O padrão é 255.</span><span class="sxs-lookup"><span data-stu-id="19e44-207">The default is 255.</span></span>  
  
 <span data-ttu-id="19e44-208">Defina este valor como 0 para desativar a seleção de recursos.</span><span class="sxs-lookup"><span data-stu-id="19e44-208">Set this value to 0 to turn off feature selection.</span></span>  
  
 <span data-ttu-id="19e44-209">[Disponível somente em algumas edições do [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]]</span><span class="sxs-lookup"><span data-stu-id="19e44-209">[Available only in some editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]]</span></span>  
  
 <span data-ttu-id="19e44-210">*MINIMUM_SUPPORT*</span><span class="sxs-lookup"><span data-stu-id="19e44-210">*MINIMUM_SUPPORT*</span></span>  
 <span data-ttu-id="19e44-211">Determina o número mínimo de casos folha necessário para gerar uma divisão na árvore de decisão.</span><span class="sxs-lookup"><span data-stu-id="19e44-211">Determines the minimum number of leaf cases that is required to generate a split in the decision tree.</span></span>  
  
 <span data-ttu-id="19e44-212">O padrão é 10.</span><span class="sxs-lookup"><span data-stu-id="19e44-212">The default is 10.</span></span>  
  
 <span data-ttu-id="19e44-213">Talvez seja necessário aumentar esse valor se o conjunto de dados for muito grande, para evitar treinamento excessivo.</span><span class="sxs-lookup"><span data-stu-id="19e44-213">You may need to increase this value if the dataset is very large, to avoid overtraining.</span></span>  
  
 <span data-ttu-id="19e44-214">*SCORE_METHOD*</span><span class="sxs-lookup"><span data-stu-id="19e44-214">*SCORE_METHOD*</span></span>  
 <span data-ttu-id="19e44-215">Determina o método usado para calcular a pontuação da divisão.</span><span class="sxs-lookup"><span data-stu-id="19e44-215">Determines the method that is used to calculate the split score.</span></span> <span data-ttu-id="19e44-216">As seguintes opções estão disponíveis:</span><span class="sxs-lookup"><span data-stu-id="19e44-216">The following options are available:</span></span>  
  
|<span data-ttu-id="19e44-217">ID</span><span class="sxs-lookup"><span data-stu-id="19e44-217">ID</span></span>|<span data-ttu-id="19e44-218">Nome</span><span class="sxs-lookup"><span data-stu-id="19e44-218">Name</span></span>|  
|--------|----------|  
|<span data-ttu-id="19e44-219">1</span><span class="sxs-lookup"><span data-stu-id="19e44-219">1</span></span>|<span data-ttu-id="19e44-220">Entropia</span><span class="sxs-lookup"><span data-stu-id="19e44-220">Entropy</span></span>|  
|<span data-ttu-id="19e44-221">3</span><span class="sxs-lookup"><span data-stu-id="19e44-221">3</span></span>|<span data-ttu-id="19e44-222">Bayesian com K2 a priori</span><span class="sxs-lookup"><span data-stu-id="19e44-222">Bayesian with K2 Prior</span></span>|  
|<span data-ttu-id="19e44-223">4</span><span class="sxs-lookup"><span data-stu-id="19e44-223">4</span></span>|<span data-ttu-id="19e44-224">Bayesiano Dirichlet Equivalente (BDE) com uniforme a priori</span><span class="sxs-lookup"><span data-stu-id="19e44-224">Bayesian Dirichlet Equivalent (BDE) with uniform prior</span></span><br /><br /> <span data-ttu-id="19e44-225">(padrão)</span><span class="sxs-lookup"><span data-stu-id="19e44-225">(default)</span></span>|  
  
 <span data-ttu-id="19e44-226">O padrão é 4 ou BDE.</span><span class="sxs-lookup"><span data-stu-id="19e44-226">The default is 4, or BDE.</span></span>  
  
 <span data-ttu-id="19e44-227">Para obter uma explicação desses métodos de pontuação, consulte [Feature Selection](../../sql-server/install/feature-selection.md).</span><span class="sxs-lookup"><span data-stu-id="19e44-227">For an explanation of these scoring methods, see [Feature Selection](../../sql-server/install/feature-selection.md).</span></span>  
  
 <span data-ttu-id="19e44-228">*SPLIT_METHOD*</span><span class="sxs-lookup"><span data-stu-id="19e44-228">*SPLIT_METHOD*</span></span>  
 <span data-ttu-id="19e44-229">Determina o método usado para dividir o nó.</span><span class="sxs-lookup"><span data-stu-id="19e44-229">Determines the method that is used to split the node.</span></span> <span data-ttu-id="19e44-230">As seguintes opções estão disponíveis:</span><span class="sxs-lookup"><span data-stu-id="19e44-230">The following options are available:</span></span>  
  
|<span data-ttu-id="19e44-231">ID</span><span class="sxs-lookup"><span data-stu-id="19e44-231">ID</span></span>|<span data-ttu-id="19e44-232">Nome</span><span class="sxs-lookup"><span data-stu-id="19e44-232">Name</span></span>|  
|--------|----------|  
|<span data-ttu-id="19e44-233">1</span><span class="sxs-lookup"><span data-stu-id="19e44-233">1</span></span>|<span data-ttu-id="19e44-234">**Binary:** Indica que, independentemente do número real de valores do atributo, a árvore deverá ser dividida em duas ramificações.</span><span class="sxs-lookup"><span data-stu-id="19e44-234">**Binary:** Indicates that regardless of the actual number of values for the attribute, the tree should be split into two branches.</span></span>|  
|<span data-ttu-id="19e44-235">2</span><span class="sxs-lookup"><span data-stu-id="19e44-235">2</span></span>|<span data-ttu-id="19e44-236">**Complete:** Indica que a árvore pode criar tantas divisões quanto há valores de atributo.</span><span class="sxs-lookup"><span data-stu-id="19e44-236">**Complete:** Indicates that the tree can create as many splits as there are attribute values.</span></span>|  
|<span data-ttu-id="19e44-237">3</span><span class="sxs-lookup"><span data-stu-id="19e44-237">3</span></span>|<span data-ttu-id="19e44-238">**Both:** Especifica que o Analysis Services pode determinar se uma divisão binária ou completa deve ser usada para produzir os melhores resultados.</span><span class="sxs-lookup"><span data-stu-id="19e44-238">**Both:** Specifies that Analysis Services can determine whether a binary or complete split should be used to produce the best results.</span></span>|  
  
 <span data-ttu-id="19e44-239">O padrão é 3.</span><span class="sxs-lookup"><span data-stu-id="19e44-239">The default is 3.</span></span>  
  
### <a name="modeling-flags"></a><span data-ttu-id="19e44-240">Sinalizadores de modelagem</span><span class="sxs-lookup"><span data-stu-id="19e44-240">Modeling Flags</span></span>  
 <span data-ttu-id="19e44-241">O algoritmo Árvores de Decisão da [!INCLUDE[msCoName](../../includes/msconame-md.md)] oferece suporte aos seguintes sinalizadores de modelagem.</span><span class="sxs-lookup"><span data-stu-id="19e44-241">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm supports the following modeling flags.</span></span> <span data-ttu-id="19e44-242">Ao criar um modelo ou uma estrutura de mineração, você define sinalizadores de modelagem para especificar como os valores em cada coluna são manipulados durante a análise.</span><span class="sxs-lookup"><span data-stu-id="19e44-242">When you create the mining structure or mining model, you define modeling flags to specify how values in each column are handled during analysis.</span></span> <span data-ttu-id="19e44-243">Para obter mais informações, consulte [Sinalizadores de modelagem &#40;Mineração de dados&#41;](modeling-flags-data-mining.md).</span><span class="sxs-lookup"><span data-stu-id="19e44-243">For more information, see [Modeling Flags &#40;Data Mining&#41;](modeling-flags-data-mining.md).</span></span>  
  
|<span data-ttu-id="19e44-244">Sinalizador de modelagem</span><span class="sxs-lookup"><span data-stu-id="19e44-244">Modeling Flag</span></span>|<span data-ttu-id="19e44-245">Descrição</span><span class="sxs-lookup"><span data-stu-id="19e44-245">Description</span></span>|  
|-------------------|-----------------|  
|<span data-ttu-id="19e44-246">MODEL_EXISTENCE_ONLY</span><span class="sxs-lookup"><span data-stu-id="19e44-246">MODEL_EXISTENCE_ONLY</span></span>|<span data-ttu-id="19e44-247">Significa que a coluna será tratada como se tivesse dois estados possíveis: `Missing` e `Existing`.</span><span class="sxs-lookup"><span data-stu-id="19e44-247">Means that the column will be treated as having two possible states: `Missing` and `Existing`.</span></span> <span data-ttu-id="19e44-248">Nulo é um valor ausente.</span><span class="sxs-lookup"><span data-stu-id="19e44-248">A null is a missing value.</span></span><br /><br /> <span data-ttu-id="19e44-249">Aplica-se às colunas de modelo de mineração.</span><span class="sxs-lookup"><span data-stu-id="19e44-249">Applies to mining model columns.</span></span>|  
|<span data-ttu-id="19e44-250">NOT NULL</span><span class="sxs-lookup"><span data-stu-id="19e44-250">NOT NULL</span></span>|<span data-ttu-id="19e44-251">Indica que a coluna não pode conter um nulo.</span><span class="sxs-lookup"><span data-stu-id="19e44-251">Indicates that the column cannot contain a null.</span></span> <span data-ttu-id="19e44-252">Um erro ocorrerá se o Analysis Services encontrar um valor nulo durante o treinamento do modelo.</span><span class="sxs-lookup"><span data-stu-id="19e44-252">An error will result if Analysis Services encounters a null during model training.</span></span><br /><br /> <span data-ttu-id="19e44-253">Aplica-se às colunas de estrutura de mineração.</span><span class="sxs-lookup"><span data-stu-id="19e44-253">Applies to mining structure columns.</span></span>|  
  
### <a name="regressors-in-decision-tree-models"></a><span data-ttu-id="19e44-254">Regressores em modelos de árvore de decisão</span><span class="sxs-lookup"><span data-stu-id="19e44-254">Regressors in Decision Tree Models</span></span>  
 <span data-ttu-id="19e44-255">Mesmo que você não use o algoritmo Regressão Linear da [!INCLUDE[msCoName](../../includes/msconame-md.md)] , qualquer modelo de árvore de decisão que tenha entradas e saídas numéricas contínuas poderá incluir nós que representem uma regressão em um atributo contínuo.</span><span class="sxs-lookup"><span data-stu-id="19e44-255">Even if you do not use the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Linear Regression algorithm, any decision tree model that has continuous numeric inputs and outputs can potentially include nodes that represent a regression on a continuous attribute.</span></span>  
  
 <span data-ttu-id="19e44-256">Não é necessário especificar que uma coluna de dados numéricos contínuos representa um regressor.</span><span class="sxs-lookup"><span data-stu-id="19e44-256">You do not need to specify that a column of continuous numeric data represents a regressor.</span></span> <span data-ttu-id="19e44-257">O algoritmo Árvores de Decisão da [!INCLUDE[msCoName](../../includes/msconame-md.md)] usará automaticamente a coluna como um regressor potencial e particionará o conjunto de dados em regiões com padrões significativos, mesmo que você não defina o sinalizador REGRESSOR na coluna.</span><span class="sxs-lookup"><span data-stu-id="19e44-257">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm will automatically use the column as a potential regressor and partition the dataset into regions with meaningful patterns even if you do not set the REGRESSOR flag on the column.</span></span>  
  
 <span data-ttu-id="19e44-258">No entanto, você pode usar o parâmetro FORCE_REGRESSOR para garantir que o algoritmo utilizará um determinado regressor.</span><span class="sxs-lookup"><span data-stu-id="19e44-258">However, you can use the FORCE_REGRESSOR parameter to guarantee that the algorithm will use a particular regressor.</span></span> <span data-ttu-id="19e44-259">Esse parâmetro só pode ser usado com os algoritmos Árvores de decisão da [!INCLUDE[msCoName](../../includes/msconame-md.md)] e Regressão Linear da [!INCLUDE[msCoName](../../includes/msconame-md.md)] .</span><span class="sxs-lookup"><span data-stu-id="19e44-259">This parameter can be used only with the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees and [!INCLUDE[msCoName](../../includes/msconame-md.md)] Linear Regression algorithms.</span></span> <span data-ttu-id="19e44-260">Quando você define o sinalizador de modelagem, o algoritmo tentará encontrar equações de regressão da forma a \* C1 + b \* C2 +... para ajustar os padrões nos nós da árvore.</span><span class="sxs-lookup"><span data-stu-id="19e44-260">When you set the modeling flag, the algorithm will try to find regression equations of the form a\*C1 + b\*C2 + ... to fit the patterns in the nodes of the tree.</span></span> <span data-ttu-id="19e44-261">A soma dos restos é calculada e, se o desvio for muito grande, será forçada uma divisão da árvore.</span><span class="sxs-lookup"><span data-stu-id="19e44-261">The sum of the residuals is calculated, and if the deviation is too great, a split is forced in the tree.</span></span>  
  
 <span data-ttu-id="19e44-262">Por exemplo, se você estiver prevendo o comportamento de compra dos clientes usando a **Renda** como um atributo e definir o sinalizador de modelagem REGRESSOR na coluna, o algoritmo primeiro tentará adequar os valores de **Renda** usando uma fórmula de regressão padrão.</span><span class="sxs-lookup"><span data-stu-id="19e44-262">For example, if you are predicting customer purchasing behavior using **Income** as an attribute, and set the REGRESSOR modeling flag on the column, the algorithm will first try to fit the **Income** values by using a standard regression formula.</span></span> <span data-ttu-id="19e44-263">Se o desvio for muito grande, a fórmula de regressão será abandonada e a árvore será dividida em outro atributo.</span><span class="sxs-lookup"><span data-stu-id="19e44-263">If the deviation is too great, the regression formula is abandoned and the tree will be split on another attribute.</span></span> <span data-ttu-id="19e44-264">O algoritmo de árvore de decisão tentará ajustar um regressor para renda em cada uma das ramificações após a divisão.</span><span class="sxs-lookup"><span data-stu-id="19e44-264">The decision tree algorithm will then try to fit a regressor for income in each of the branches after the split.</span></span>  
  
## <a name="requirements"></a><span data-ttu-id="19e44-265">Requisitos</span><span class="sxs-lookup"><span data-stu-id="19e44-265">Requirements</span></span>  
 <span data-ttu-id="19e44-266">Um modelo de árvore de decisão deve conter uma coluna de chave, colunas de entrada e pelo menos uma coluna previsível.</span><span class="sxs-lookup"><span data-stu-id="19e44-266">A decision tree model must contain a key column, input columns, and at least one predictable column.</span></span>  
  
### <a name="input-and-predictable-columns"></a><span data-ttu-id="19e44-267">Colunas de entrada e colunas previsíveis</span><span class="sxs-lookup"><span data-stu-id="19e44-267">Input and Predictable Columns</span></span>  
 <span data-ttu-id="19e44-268">O algoritmo Árvores de Decisão da [!INCLUDE[msCoName](../../includes/msconame-md.md)] oferece suporte a colunas de entrada e colunas previsíveis específicas que são listadas na tabela a seguir.</span><span class="sxs-lookup"><span data-stu-id="19e44-268">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm supports the specific input columns and predictable columns that are listed in the following table.</span></span> <span data-ttu-id="19e44-269">Para obter mais informações sobre o significado dos tipos de conteúdo quando usados em um modelo de mineração, consulte [Tipos de conteúdo &#40;Mineração de dados&#41;](content-types-data-mining.md).</span><span class="sxs-lookup"><span data-stu-id="19e44-269">For more information about what the content types mean when used in a mining model, see [Content Types &#40;Data Mining&#41;](content-types-data-mining.md).</span></span>  
  
|<span data-ttu-id="19e44-270">Coluna</span><span class="sxs-lookup"><span data-stu-id="19e44-270">Column</span></span>|<span data-ttu-id="19e44-271">Tipos de conteúdo</span><span class="sxs-lookup"><span data-stu-id="19e44-271">Content types</span></span>|  
|------------|-------------------|  
|<span data-ttu-id="19e44-272">Atributo de entrada</span><span class="sxs-lookup"><span data-stu-id="19e44-272">Input attribute</span></span>|<span data-ttu-id="19e44-273">Contínuo, cíclico, discreto, diferenciado, chave, ordenado, tabela</span><span class="sxs-lookup"><span data-stu-id="19e44-273">Continuous, Cyclical, Discrete, Discretized, Key, Ordered, Table</span></span>|  
|<span data-ttu-id="19e44-274">Atributo previsível</span><span class="sxs-lookup"><span data-stu-id="19e44-274">Predictable attribute</span></span>|<span data-ttu-id="19e44-275">Contínuo, cíclico, discreto, diferenciado, ordenado, tabela</span><span class="sxs-lookup"><span data-stu-id="19e44-275">Continuous, Cyclical, Discrete, Discretized, Ordered, Table</span></span>|  
  
> [!NOTE]  
>  <span data-ttu-id="19e44-276">Os tipos de conteúdo Cíclico e Ordenado têm suporte, mas o algoritmo os trata como valores discretos e não executa processamento especial.</span><span class="sxs-lookup"><span data-stu-id="19e44-276">Cyclical and Ordered content types are supported, but the algorithm treats them as discrete values and does not perform special processing.</span></span>  
  
## <a name="see-also"></a><span data-ttu-id="19e44-277">Consulte Também</span><span class="sxs-lookup"><span data-stu-id="19e44-277">See Also</span></span>  
 <span data-ttu-id="19e44-278">[Algoritmo árvores de decisão da Microsoft](microsoft-decision-trees-algorithm.md) </span><span class="sxs-lookup"><span data-stu-id="19e44-278">[Microsoft Decision Trees Algorithm](microsoft-decision-trees-algorithm.md) </span></span>  
 <span data-ttu-id="19e44-279">[Exemplos de consulta de modelo de árvores de decisão](decision-trees-model-query-examples.md) </span><span class="sxs-lookup"><span data-stu-id="19e44-279">[Decision Trees Model Query Examples](decision-trees-model-query-examples.md) </span></span>  
 [<span data-ttu-id="19e44-280">Conteúdo do modelo de mineração para modelos de árvore de decisão &#40;Analysis Services – Data Mining&#41;</span><span class="sxs-lookup"><span data-stu-id="19e44-280">Mining Model Content for Decision Tree Models &#40;Analysis Services - Data Mining&#41;</span></span>](mining-model-content-for-decision-tree-models-analysis-services-data-mining.md)  
  
  
